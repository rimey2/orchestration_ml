{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "intro"
   },
   "source": [
    "L'optimisation bay√©sienne est une m√©thode permettant de d√©terminer les hyper-param√®tres optimaux d'un mod√®le en utilisant les outils de statistiques bay√©siennes. Leur principal int√©r√™t contrairement aux recherches par grille est d'utiliser l'information acquise au cours de l'optimisation pour d√©terminer les prochains hyper-param√®tres √† tester.\n",
    "\n",
    "<blockquote><p>üôã <b>Ce que nous allons faire</b></p>\n",
    "<ul>\n",
    "    <li>D√©couvrir l'approche bay√©sienne d'optimisation des hyper-param√®tres</li>\n",
    "    <li>Lancer une recherche TPE sur LightGBM</li>\n",
    "    <li>Calibrer un mod√®le sur les meilleurs hyper-param√®tres</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/cmqZM1lFsKHqo/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche bay√©sienne\n",
    "\n",
    "Dans un mod√®le, nous devons diff√©rencier deux types de param√®tres.\n",
    "\n",
    "- En statistique param√©trique, le mod√®le est une fonction de param√®tre $\\theta \\in \\Theta$ : les composantes de $\\theta$ repr√©sentent **les param√®tres du mod√®le**. Ils sont estim√©s par des algorithmes d'optimisation num√©rique.\n",
    "- Les **hyper-param√®tres** sont des valeurs d'ajustement du mod√®le qui sont fixes et qui ne sont pas estim√©s par les algorithmes d'optimisation, mais utilis√©s par ces derniers.\n",
    "\n",
    "Le choix des hyper-param√®tres aura donc une influence sur la fa√ßon dont le mod√®le est entra√Æn√© et automatiquement sur ses performances.\n",
    "\n",
    "La difficult√© des hyper-param√®tres, c'est que contrairement aux param√®tres du mod√®le, il n'y a aucun moyen de savoir si un jeu d'hyper-param√®tres est optimal ou non.\n",
    "\n",
    "Pour cela, une solution consiste √† tester plusieurs jeux d'hyper-param√®tres et de choisir celui qui maximise les performances.\n",
    "\n",
    "Il y a autant d'entra√Ænement de mod√®le √† effectuer qu'il y a de jeux d'hyper-param√®tres. Ainsi, une question se pose : **comment d√©terminer le jeu d'hyper-param√®tre optimal le plus rapidement ?**\n",
    "\n",
    "Jusqu'ici, la plupart des approches utilise des recherches par grille (d√©terministes ou al√©atoires) qui consiste √† tester un nombre de points finis de jeux d'hyper-param√®tres. Nous allons voir ici une autre approche, plus efficace dans certains cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction substitut\n",
    "\n",
    "Dans l'approche bay√©sienne, nous allons ¬´ capitaliser ¬ª sur les r√©sultats obtenus aux pr√©c√©dents jeux d'hyper-param√®tres. Autrement dit, √† chaque jeu d'hyper-param√®tres, on cherche √† calculer le prochain score √† partir des hyper-param√®tres.\n",
    "\n",
    "$$\\tau(\\text{Hyper-param√®tres}) \\overset{\\Delta}{=} \\mathbb{P}(\\text{Score}|\\text{Hyper-param√®tres})$$\n",
    "\n",
    "En pratique, nous ne pouvons pas calculer cette loi bay√©sienne. Pour cela, nous introduisons une fonction moins complexe mais suffisamment similaire que l'on cherchera √† optimiser. Cette fonction est appel√©e **substitut** (ou **surrogate**).\n",
    "\n",
    "Le fait de rajouter un substitut fait que les calculs pour trouver le prochain $S_{\\text{Opt}}^{(t)}$ (jeu d'hyper-param√®tres) √† tester sur un mod√®le **sont assez importants**. Mais ces temps de calculs sont compens√©s par une recherche d'un jeu d'hyper-param√®tres optimal en un nombre d'it√©rations inf√©rieurs que pour les m√©thodes de recherche par grille.\n",
    "\n",
    "L'optimisation bay√©sienne prend tout son sens dans la recherche des hyper-param√®tres optimaux, puisque les temps de calcul de $\\tau(S_{\\text{Opt}}^{(t)})$ sont d√©j√† consid√©rables. En revanche, cette m√©thode n'aurait aucun int√©r√™t dans un cadre classique d'optimisation num√©rique ou de nombreuses it√©rations sont n√©cessaires pour s'approcher d'un √©ventuel extremum global.\n",
    "\n",
    "Il existe plusieurs algorithmes bay√©siens qui permettent d'estimer un jeu d'hyper-param√®tres optimal. L'algorithme SMBO pour Sequential Model-Based Optimization est un des plus utilis√©s en Machine Learning.\n",
    "\n",
    "### Algorithme SMBO\n",
    "\n",
    "L'algorithme Sequential Model-Based Optimization (SMBO) est une famille d'algorithmes bay√©siens o√π l'objectif est de maximiser $\\tau$ en cherchant √† minimiser une fonction (par exemple $l$) par un mod√®le substitut (*surrogate*).\n",
    "\n",
    "Tout d'abord, la base de connaissance $\\mathcal{H}$ des hyper-param√®tres pour le substitut $\\tau$ est initialis√© √† l'ensemble vide. Il est √©galement n√©cessaire de fournir un nombre d'it√©rations maximale $T$ ainsi qu'un mod√®le initial $M_0$ **pour le substitut**. La m√©thode SMBO s'ex√©cute ensuite de la fa√ßon suivante √† chaque it√©ration $t$.\n",
    "\n",
    "1. Estimer $S_{\\text{Opt}}^{(t)}=\\text{argmax}_S l(S, M_{t-1})$\n",
    "2. Calculer le score $R$ d'un mod√®le $\\hat{f}$ entra√Æn√© avec le jeu d'hyper-param√®tres $S_{\\text{Opt}}^{(t)}$\n",
    "3. Mettre √† jour la base de connaissances : $\\mathcal{H}=\\mathcal{H} \\cup (S_{\\text{Opt}}^{(t)}, R)$\n",
    "4. Estimer un nouveau mod√®le $M_t$ pour le substitut √† partir de $\\mathcal{H}$.\n",
    "\n",
    "En pratique, les mod√®les substituts utilis√©s sont les processus Gaussiens (GP), des Random Forests (RF) ou des Tree of Parzen Estimators (TPE).\n",
    "\n",
    "### Fonction de s√©lection\n",
    "\n",
    "La fonction de s√©lection (ou d'acquisition) fournit un crit√®re quantitatif dans l'algorithme SMBO : c'est elle qui permet de choisir le prochain jeu d'hyper-param√®tres √† tester (√©tape 1). Une fonction de s√©lection particuli√®rement utilis√©e est l'Expected Improvement :\n",
    "\n",
    "<p>\n",
    "$$\\text{EI}_{y^*}(u)=\\int_{-\\infty}^{y^*} (y^*-y)p(y|u)dy$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    o√π $y^*$ est un seuil maximal et $p(y|u)$ la <b>densit√© du mod√®le substitut</b> √©valu√© en $y$ sachant $u$. L'objectif est donc de maximiser $\\text{EI}_{y^*}$ sachant $u$, qui dans SMBO repr√©sentera $S_{\\text{Opt}}^{(t)}$.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    Intuitivement, si $p(y|u) =0$ pour tout $y < y^*$, alors le jeu d'hyper-param√®tres $u := S_{\\text{Opt}}^{(t)}$ est consid√©r√© comme optimal puisque aucune am√©lioration sur le score ne peut √™tre apport√©.\n",
    "    </p>\n",
    "\n",
    "<p>\n",
    "    √Ä l'inverse, si $\\text{EI}_{y^*}(u)>0$, c'est qu'il existe un meilleur jeu d'hyper-param√®tres $u$ pouvant amener √† une augmentation du score par rapport au jeu actuel. Sans une introduction d'un nombre d'it√©rations maximale, les temps de calcul pourraient √™tre bien trop √©lev√©s, non seulement parce qu'il est rare d'obtenir une valeur exacte en optimisation, mais √©galement parce que l'entra√Ænement du mod√®le $\\hat{f}$ peut lui aussi d√©pendre de variations al√©atoires (propre √† ce dernier) et toujours engendrer des variations de scores pour un m√™me $u$.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "break": "new"
   },
   "source": [
    "## Application avec Tree of Parzen Estimators\n",
    "\n",
    "Nous allons ici √©tudier le cas o√π le mod√®le substitut est un Tree of Parzen Estimators (TPE). L'id√©e des estimateurs Parzen est proche de l'optimisation bay√©sienne, bien qu'il y ait une diff√©rence sur le plan th√©orique.\n",
    "\n",
    "Dans cette approche, plut√¥t que de construire un mod√®le bay√©sien dans l'√©tape 4 (et donc de mod√©liser $l(S_{\\text{Opt}}^{(t)})$), on calcule directement cette quantit√© √† partir des r√®gles de calcul bay√©siennes.\n",
    "\n",
    "$$l(S_{\\text{Opt}}^{(t)})=p(y|x)=\\frac{p(x|y)p(y)}{p(x)}$$\n",
    "\n",
    "La probabilit√© d'obtenir un jeu d'hyper-param√®tres en fonction des performances du mod√®le avec $l$ est donn√© par\n",
    "\n",
    "<p>\n",
    "    $$p(x|y)=\\left\\{\\begin{matrix}\n",
    "l(x) & \\text{si } y < y^* \\\\ \n",
    "g(x) & \\text{si } y \\geq y^*\n",
    "\\end{matrix}\\right.$$\n",
    "    </p>\n",
    "\n",
    "<p>\n",
    "    o√π $y^*$ est un seuil, similaire √† celui de $\\text{EI}$, et $y$ √©tant ici la perte du mod√®le dans le cadre de l'optimisation des hyper-param√®tres. L'int√©r√™t de cette repr√©sentation est de construire deux distributions $l$ et $g$ qui correspondent aux situations o√π la perte du mod√®le est inf√©rieure au seuil $y^*$ et inversement.\n",
    "    </p>\n",
    "\n",
    "Maintenant, reprenons le calcul de l'Expected Improvement et rempla√ßons $p(y|u)$ par le calcul bay√©sien.\n",
    "\n",
    "<p>\n",
    "    $$\n",
    "\\begin{eqnarray*}\n",
    "\\text{EI}_{y^*}(u) & = & \\int_{-\\infty}^{y^*} (y^*-y)\\frac{p(u|y)p(y)}{p(u)}dy \\\\\n",
    "& = & \\frac{l(u)}{p(u)}  \\int_{-\\infty}^{y^*} (y^*-y)p(y)dy \\\\\n",
    "& = & \\frac{l(u)}{p(u)} \\left ( \\gamma y^* - \\int_{-\\infty}^{y^*} yp(y)dy \\right)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "    </p>\n",
    "\n",
    "Or\n",
    "\n",
    "$$p(u)=\\int p(u|y)p(y)dy=\\gamma l(u)+(1-\\gamma)g(u)$$\n",
    "\n",
    "donc\n",
    "\n",
    "<p>\n",
    "    $$\\text{EI}_{y^*}(u) = \\frac{\\gamma y^* l(u)-l(u) \\int_{-\\infty}^{y^*} y p(y)dy}{\\gamma l(u)+(1-\\gamma)g(u)} \\propto \\left( \\gamma + \\frac{g(u)}{l(u)}(1-\\gamma) \\right)^{-1}$$\n",
    "    </p>\n",
    "\n",
    "<p>\n",
    "    Ce qui est int√©ressant ici, c'est que $\\text{EI}_{y^*}(u)$ est proportionnel √† la quantit√© $\\frac{l(u)}{g(u)}$. Et c'est exactement la logique qui se cache derri√®re $l$ et $g$, car $l$ correspond √† des situations o√π les performances du mod√®le √©taient meilleures car la perte associ√©e √©tait plus faible. En cherchant √† maximiser $\\frac{l(u)}{g(u)}$, et donc l'Expected Improvement, on s'assure qu'en s√©lectionnant le prochain jeu d'hyper-param√®tres, on a plus de chances de maximiser les performances en s√©lectionnant des hyper-param√®tres dont la perte est encore plus faible.\n",
    "    </p>\n",
    "\n",
    "Un des principaux avantages de cette m√©thode est que contrairement √† l'optimisation bay√©sienne, **il n'y a pas de mod√®le substitut √† calibrer** comme un Processus Gaussien, ce qui r√©duit les temps de calcul. On se base uniquement sur un simple calcul bay√©sien. L'appellation *Tree-structured* vient du fait que les estimateurs Parzen sont des <a href=\"https://fr.wikipedia.org/wiki/Estimation_par_noyau#:~:text=En%20statistique%2C%20l'estimation%20par,en%20tout%20point%20du%20support.\" target=\"_blank\">estimateurs de densit√© √† noyau</a>. Ainsi, la succession chronologique du choix des hyper-param√®tres forme une structure d'arbre pour l'espace des hyper-param√®tres.\n",
    "\n",
    "Appliquons un TPE pour le mod√®le LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae6e8f4e665d9b10"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons charger la base d'apprentissage $(X,y)$ qui sera utilis√© lors de l'optimisation bay√©sienne avec $k$-Fold, et les sous-ensembles d'entra√Ænement et de test pour calibrer le mod√®le une fois les meilleurs hyper-param√®tres obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17b8e297de84c1d7"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.expanduser(\"~/data/X.csv\"))\n",
    "y = pd.read_csv(os.path.expanduser(\"~/data/y.csv\"))\n",
    "\n",
    "X_train = pd.read_csv(os.path.expanduser(\"~/data/X_train.csv\"))\n",
    "X_test = pd.read_csv(os.path.expanduser(\"~/data/X_test.csv\"))\n",
    "y_train = pd.read_csv(os.path.expanduser(\"~/data/y_train.csv\")).values.flatten()\n",
    "y_test = pd.read_csv(os.path.expanduser(\"~/data/y_test.csv\")).values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D√©finissons l'espace de recherche qui sera utilis√© par l'optimiseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f176dac91c5f8de6"
   },
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "MODEL_SPECS = {\n",
    "    \"name\": \"LightGBM\",\n",
    "    \"class\": LGBMClassifier,\n",
    "    \"max_evals\": 20,\n",
    "    \"params\": {\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.001, 1),\n",
    "        \"num_iterations\": hp.quniform(\"num_iterations\", 100, 1000, 20),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 4, 12, 6),\n",
    "        \"num_leaves\": hp.quniform(\"num_leaves\", 8, 128, 10),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.3, 1),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "        \"min_child_samples\": hp.quniform(\"min_child_samples\", 1, 20, 10),\n",
    "        \"reg_alpha\": hp.choice(\"reg_alpha\", [0, 1e-1, 1, 2, 5, 10]),\n",
    "        \"reg_lambda\": hp.choice(\"reg_lambda\", [0, 1e-1, 1, 2, 5, 10]),\n",
    "    },\n",
    "    \"override_schemas\": {\n",
    "        \"num_leaves\": int, \"min_child_samples\": int, \"max_depth\": int, \"num_iterations\": int\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourra retrouver la <a href=\"https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier\" target=\"_blank\">liste des hyper-param√®tres de LightGBM</a>.\n",
    "\n",
    "Pour faciliter la maintenance du code, nous **encapsulons** le processus d'optimisation dans une fonction `optimize_hyp` qui n√©cessite plusieurs arguments.\n",
    "\n",
    "- `instance` est la classe h√©rit√© de `BaseEstimator` de `scikit-learn` pour instancier un mod√®le.\n",
    "- `training_set` est la base d'apprentissage $(X,y)$.\n",
    "- `search_space` est l'espace de recherche pour l'optimiseur.\n",
    "- `metric` est la m√©trique √† utiliser pour calculer le score.\n",
    "- `evals` est le nombre d'it√©rations de l'optimiseur.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Dans <code>hyperopt</code>, on cherche √† minimiser une fonction objectif : il faut donc renvoyer l'inverse additif dans le cas o√π la m√©trique utilis√©e est un score.\n",
    "</div>\n",
    "\n",
    "Dans certains cas, les hyper-param√®tres de l'espace de recherche ne sont pas toujours entiers ($10.0$ au lieu de $10$), ce qui peut g√©n√©rer des erreurs. Le champ `override_schemas` contient une liste d'hyper-param√®tres pour lesquels le conversion en nombre entier est explicite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d957c26d9f6da2b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "def optimize_hyp(instance, training_set, search_space, metric, evals=10):\n",
    "    # Fonction que l'on souhaite minimiser (inverse de tau)\n",
    "    def objective(params):\n",
    "        for param in set(list(MODEL_SPECS[\"override_schemas\"].keys())).intersection(set(params.keys())):\n",
    "            cast_instance = MODEL_SPECS['override_schemas'][param]\n",
    "            params[param] = cast_instance(params[param])\n",
    "            \n",
    "        # On r√©p√®te 3 fois un 5-Fold\n",
    "        rep_kfold = RepeatedKFold(n_splits=4, n_repeats=1)\n",
    "        scores_test = []\n",
    "        for train_I, test_I in rep_kfold.split(X):\n",
    "            X_fold_train = X.iloc[train_I, :]\n",
    "            y_fold_train = y.iloc[train_I]\n",
    "            X_fold_test = X.iloc[test_I, :]\n",
    "            y_fold_test = y.iloc[test_I]\n",
    "\n",
    "            # On entra√Æne un LightGBM avec les param√®tres par d√©faut\n",
    "            model = LGBMClassifier(**params, objective=\"binary\", verbose=-1)\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "            # On calcule le score du mod√®le sur le test\n",
    "            scores_test.append(\n",
    "                metric(y_fold_test, model.predict(X_fold_test))\n",
    "            )\n",
    "\n",
    "        return np.mean(scores_test)\n",
    "\n",
    "    return fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En appelant la fonction `optimize_hyp`, les meilleurs hyper-param√®tres vont √™tre recherch√©s puis retourn√©s une fois l'optimisation termin√©e. Nous r√©cup√©rerons les hyper-param√®tres optimaux dans la variable `optimum_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c80ba470a4c0464c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "optimum_params = optimize_hyp(\n",
    "    MODEL_SPECS['class'],\n",
    "    training_set=(X_train, y_train),\n",
    "    search_space=MODEL_SPECS[\"params\"],\n",
    "    metric=lambda x, y: -f1_score(x, y), # Probl√®me de minimisation = inverse du score\n",
    "    evals=MODEL_SPECS[\"max_evals\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons les hyper-param√®tres optimaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "873e5bbad391611c"
   },
   "outputs": [],
   "source": [
    "optimum_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous les connaissons, nous pouvons entra√Æner un LightGBM avec ces hyper-param√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7477db4a76af8304"
   },
   "outputs": [],
   "source": [
    "# Chaque param√®tres dont le sch√©ma est surcharg√© est cast√© vers le bon type\n",
    "for param in MODEL_SPECS['override_schemas']:\n",
    "    cast_instance = MODEL_SPECS['override_schemas'][param]\n",
    "    optimum_params[param] = cast_instance(optimum_params[param])\n",
    "\n",
    "model = LGBMClassifier(**optimum_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6faec1e8583a412a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "print(\"F1 Score : {:2.1f}%\".format(f1_score(y_test, model.predict(X_test)) * 100))\n",
    "print(\"Precision : {:2.1f}%\".format(precision_score(y_test, model.predict(X_test)) * 100))\n",
    "print(\"Recall : {:2.1f}%\".format(recall_score(y_test, model.predict(X_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui est int√©ressant ici, c'est qu'en cherchant √† maximiser le F1 score, nous avons obtenu un meilleur rappel, mais la pr√©cision est moins √©lev√©.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Il ne faudrait surtout pas n'utiliser que le rappel pour optimiser le mod√®le : on obtiendrai un mod√®le avec potentiellement une mauvaise pr√©cision.\n",
    "</div>\n",
    "\n",
    "Au final, en comparaison avec le mod√®le non optimis√©, nous n'avons que tr√®s peu gagn√© au niveau du F1 Score, mais nous avons en revanche un meilleur rappel, qui √©tait l'objectif initial puisque c'est surtout cette m√©trique qu'il faut maximiser.\n",
    "\n",
    "Nous allons enregistrer le mod√®le au format `pkl`, que l'on r√©utilisera pour l'√©valuer et l'interpr√©ter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4e52814a52a3301"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, os.path.expanduser(\"~/data/model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "break": "new"
   },
   "source": [
    "## Courbe de calibration\n",
    "\n",
    "Les courbes de calibration permettent de comparer les proportions d'observations pr√©dites positivement et d'observations appartenant √† la classe positive √† partir du seuil $\\alpha$ d√©finissant la fronti√®re du classifieur.\n",
    "\n",
    "$$CC(\\alpha)=\\frac{1}{n} |\\{ \\hat{f}(x) \\geq \\alpha : x \\in X \\}|$$\n",
    "\n",
    "Regardons la courbe de calibration de notre mod√®le optimis√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49817ce1ef91cbc5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=20)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\", alpha=0.6)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.xlabel(\"Predicted probabilites\")\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce que nous voyons, c'est qu'√† partir de $40\\%$, le mod√®le contient les bonnes proportions d'observations √† la fois positives et n√©gatives : il n'y a donc pas de sur-repr√©sentation d'une certaine classe lorsque les probabilit√©s pr√©dites sont sup√©rieures √† $40\\%$.\n",
    "\n",
    "En dessous de cette valeur, nous observations quelques disparit√©s, mais qui restent n√©anmoins ma√Ætris√©es sur l'ensemble des probabilit√©s. Au vu de cette courbe, nous pouvons conclure que les proportions de classes positives sont globalement respect√©es selon les probabilit√©s pr√©dites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "ending"
   },
   "source": [
    "## ‚úîÔ∏è Conclusion\n",
    "\n",
    "L'optimisation des hyper-param√®tres peut demander un effort au d√©but, mais une fois mise en place, elle constitue une v√©ritable force d'automatisation.\n",
    "\n",
    "- Nous avons vu l'approche bay√©sienne pour l'optimisation des hyper-param√®tres d'un mod√®le de Machine Learning.\n",
    "- Nous avons optimis√© un LightGBM avec une approche Tree of Parzen Estimators.\n",
    "- Le mod√®le optimis√© a √©t√© enregistr√© au format Pickle pour √™tre r√©-utilis√© par la suite.\n",
    "\n",
    "> ‚û°Ô∏è Derni√®re √©tape dans la construction du mod√®le : <b>validation et interpr√©tation</b>."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "√âditer les M√©ta-Donn√©es",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
