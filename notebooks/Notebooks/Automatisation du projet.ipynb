{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f72a0740203eb530"
   },
   "source": [
    "Comme nous avons pu le voir, Apache Airflow est un outil tr√®s puissant pour automatiser des workflows. Il permet aussi bien d'automatiser des pipelines ETL que des s√©quences d'entrainement de mod√®les. De plus, son int√©gration avec diff√©rentes applications et services (donc ceux de Google Cloud) le rendent tr√®s op√©rationnel.\n",
    "\n",
    "<blockquote><p>üôã <b>Ce que nous allons faire</b></p>\n",
    "<ul>\n",
    "    <li>Utiliser les op√©rateurs Google Cloud pr√©sents sur Apache Airflow</li>\n",
    "    <li>D√©clencher le pipeline ML sur Airflow dans les deux environnements</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/7zYmz8wSLMIV7qpgSU/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La d√©rive de mod√®le\n",
    "\n",
    "Airflow va √™tre tr√®s utile pour contrer un ph√©nom√®ne tr√®s pr√©sent dans les environnements de production : la **d√©rive de mod√®le** (ou *model drift*). Il y a en r√©alit√© deux types de d√©rives qui peuvent survenir.\n",
    "\n",
    "- La **d√©rive conceptuelle** : dans ce cas de figure, les propri√©t√©s statistiques de la variables r√©ponse √©voluent. C'est le cas par exemple o√π l'on consid√®re que la variable r√©ponse n'a plus la m√™me signification au cours du temps. Un exemple classique est la notion de spam sur les r√©seaux sociaux : au tout d√©but, les spams consid√©r√©s √©taient uniquement les messages comportant des caract√®res al√©atoires. En avan√ßant dans le temps, les spams ont englob√©s de plus en plus de cas, et plus seulement des messages al√©atoires. Puisqu'il y a une **red√©finition de la variable r√©ponse**, le mod√®le est, en soit, toujours coh√©rent dans ses pr√©dictions, mais dans notre fait, ses pr√©dictions n'ont plus la m√™me valeur par rapport au probl√®me pos√©.\n",
    "- La **d√©rive des donn√©es** : √† l'inverse, c'est lorsque les propri√©t√©s statistiques de l'estimateur/mod√®le √©voluent. Automatiquement, le mod√®le n'est donc plus en phase avec le ph√©nom√®ne sous-jacent. Cela est d'autant plus fort qu'il y a une composante temporelle. Prenons par exemple un mod√®le qui cherche √† pr√©dire la dur√©e de trajet dans une ville √† forte densit√© (Paris, Lyon, etc). Au moins d'ao√ªt, il y a par exemple beaucoup moins de circulation qu'en f√©vrier. Un mod√®le, qui se serait entra√Æn√© sur quelques mois d'historique, ne fournirait pas des pr√©dictions satisfaisantes en plein √©t√©. Cela est du au fait que la dur√©e d'un trajet d√©pend de la circulation, qui elle-m√™me d√©pend (en partie) du moment de l'ann√©e. Il serait donc indispensable de mettre √† jour le mod√®le avec des donn√©es ¬´ plus fra√Æches ¬ª.\n",
    "\n",
    "La m√©thode la plus efficace pour corriger ces deux d√©rives est d'entra√Æner le mod√®le r√©guli√®rement avec des donn√©es r√©centes.\n",
    "\n",
    "> ‚ùì Est-ce que cela veut dire que l'on oublie les donn√©es plus ancienne ?\n",
    "\n",
    "Pas forc√©ment. Pour notre exemple de pr√©diction de comportement utilisateur, on souhaite bien √©videmment avoir l'information des comportements r√©cents, car cela refl√®te le plus fid√®lement possible les utilisateurs. Des comportements d'il y a deux mois ou depuis No√´l ne sont pas forc√©ment pertinent √† l'heure actuelle.\n",
    "\n",
    "Dans d'autres situations, n√©anmoins, il est toujours utile de garder une *m√©moire* des donn√©es plus anciennes. On retrouve alors des situations o√π l'on pond√©rise les donn√©es en fonction de leur anciennet√©, de sorte √† conserver des donn√©es anciennes sans pour autant leur donner la m√™me importance que les donn√©es plus r√©centes.\n",
    "\n",
    "Maintenant que nous avons la solution, une question fatidique se pose.\n",
    "\n",
    "> ‚ùì √Ä quelle fr√©quence doit-on rafra√Æchir le mod√®le ?\n",
    "\n",
    "Et forc√©ment, il n'y a pas de r√©ponse toute faite. üòÖ\n",
    "En principe, c'est bien entendu le domaine d'application et le cas d'usage qui va d√©finir cette fr√©quence de rafra√Æchissement. Dans notre exemple de ECommerce, on souhaite avoir un comportement utilisateur assez r√©cent, sans pour autant prendre trop ancien : si l'on consid√©rait un rafra√Æchissement tous les deux mois, les √©v√©nements particuliers comme No√´l seront absorb√©s par tous les autres √©v√©nements. En ne prenant que quelques jours (2 ou 3), on ne prends plus en compte le cycle hebdomaire semaine/week-end, qui peut potentiellement influencer le comportement des utilisateurs.\n",
    "\n",
    "Le plus adapt√© serait donc de consid√©rer une fr√©quence de rafra√Æchissement de 1 √† 2 semaines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatisation sur Airflow\n",
    "\n",
    "Rappelons-nous de l'automatisation d√©j√† mise en place dans notre infrastructure. D'une part, le pipeline de pr√©-production, ex√©cut√© √† chaque mise √† jour d'un code sur un des d√©p√¥ts (du mod√®le ou de l'API). Le pipeline de pr√©-production est la succession du pipeline CI/CD construit pour entra√Æner le mod√®le et l'envoyer vers MLflow, avec le pipeline qui va automatiquement d√©ployer une image Docker de l'API sur Cloud Run.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/pipeline_preprod.png\" />\n",
    "\n",
    "De mani√®re quasi-symm√©trique, nous avons √©galement le pipeline de production\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/pipeline_prod1.png\" />\n",
    "\n",
    "Les petites diff√©rences r√©sident dans les branches consid√©r√©es (`staging` ou `master`) des projets Git, ainsi que sur la plateforme cible qui est Cloud Run dans l'environnement de pr√©-production et Kubernetes dans l'environnement de production.\n",
    "\n",
    "Le principal avantage de nos deux pipelines, c'est que mis √† part les d√©clenchements qui sont manuels lors d'un push sur Git, toutes les autres √©tapes sont r√©alis√©s automatiquement. En d'autres termes, il n'y a **pas besoin de r√©-√©crire toutes les √©tapes** : il nous suffirait de d√©clencher automatiquement le build sur Cloud Build pour que les pipelines soient ensuite ex√©cut√© en int√©gralit√© de mani√®re automatis√©e.\n",
    "\n",
    "Et c'est justement notre int√©r√™t ici : √† l'aide d'Airflow, nous allons simplement d√©clencher le build qui va construire le mod√®le (`purchase-predict`). Avec les pipelines CI/CD que nous avons d√©j√† configur√©, le mod√®le sera ensuite envoy√© sur Airflow puis l'API, √† son tour, sera conteneuris√©e pour √™tre ensuite d√©ploy√©e vers la plateforme cible associ√©e. Nous avons donc uniquement besoin de d√©clencher un build via Airflow pour lancer toute la s√©quence de mani√®re automatis√©e.\n",
    "\n",
    "> ‚ùì Mais les donn√©es, elles, ne changent pas ?\n",
    "\n",
    "Et oui ! Rappelons-nous que les donn√©es les plus √† jour sont stock√©es sur une table BigQuery !\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/bigquery_10.jpg\" />\n",
    "\n",
    "La seule hypoth√®se que nous avons ici est que les donn√©es arrivent *en continu* sur cette table par d'autres applications. Sauf que cette table ne contient pas les donn√©es ¬´ pr√™tes √† l'emploi ¬ª. Si l'on se rappelle bien, nous avions r√©alis√© un script Spark qui allait justement faire tout le travail de transformation de donn√©es pour ensuite cr√©er les fichiers CSV dans le bucket.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/dataproc_spark2.png\" />\n",
    "\n",
    "Ces fichiers CSV qui sont ensuite lus par Kedro dans le pipeline `loading` sur le projet `purchase-predict`, et la suite que nous connaissons tr√®s bien. üòâ\n",
    "\n",
    "Il nous faut donc, avant de d√©clencher le build, ex√©cuter la t√¢che Spark qui va r√©cup√©rer les donn√©es depuis la table BigQuery avec une intervalle de dates sp√©cifi√© pour ensuite transformer les donn√©es et exporter le tout sur un bucket. Ainsi, Airflow devra au pr√©alable ex√©cuter la t√¢che PySpark dans un cluster Dataproc avant de d√©clencher le build, que nous pouvons r√©sumer dans le sch√©ma suivant.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du DAG\n",
    "\n",
    "Pour l'instant, int√©ressons-nous uniquement au DAG qui va d√©clencher le pipeline ML dans l'environnement de pr√©-production. Nous pouvons d√©composer notre DAG de mani√®re successive.\n",
    "\n",
    "- Cr√©ation d'un cluster Dataproc.\n",
    "- Une fois le cluster cr√©e, on envoie la t√¢che PySpark avec les arguments de temporalit√©.\n",
    "- On d√©truit le cluster, et en parall√®le, on ex√©cute le build.\n",
    "\n",
    "Comme mentionn√© plus haut, Airflow dispose <a href=\"https://airflow.apache.org/docs/apache-airflow-providers-google/stable/operators/cloud/dataproc.html\" target=\"_blank\">d'op√©rateurs Dataproc</a> pour cr√©er, supprimer des clusters Dataproc ou encore envoyer des t√¢ches. Pour cela, nous devons installer les d√©pendances suppl√©mentaires Google Cloud sous Airflow."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "pip install apache-airflow-providers-google==5.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    La r√©f√©rence de tous les op√©rateurs et hooks est <a href=\"https://airflow.apache.org/docs/apache-airflow-providers/operators-and-hooks-ref/index.html\" target=\"_blank\">disponible ici</a>.\n",
    "</div>\n",
    "\n",
    "Commen√ßons par construire un premier DAG `pipeline_ml_staging` avec seulement deux t√¢ches : une pour cr√©er un cluster Dataproc, et une autre pour le supprimer."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "python"
   },
   "source": [
    "import os\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.models import Variable\n",
    "from airflow.utils.dates import days_ago\n",
    "from datetime import timedelta\n",
    "from google.protobuf.duration_pb2 import Duration\n",
    "\n",
    "from airflow.utils import trigger_rule\n",
    "from airflow.providers.google.cloud.operators.dataproc import (\n",
    "    DataprocCreateClusterOperator,\n",
    "    DataprocDeleteClusterOperator\n",
    ")\n",
    "\n",
    "DAG_NAME = os.path.basename(__file__).replace(\".py\", \"\")\n",
    "BUCKET = \"blent-formation-ml-engineer-data\"\n",
    "CLUSTER_NAME_TEMPLATE = \"purchase-predict-cluster-staging-\"\n",
    "CLUSTER_CONFIG = {\n",
    "    \"software_config\": {\n",
    "        \"image_version\": \"2.0-debian10\"\n",
    "    },\n",
    "    \"master_config\": {\n",
    "        \"num_instances\": 1,\n",
    "        \"machine_type_uri\": \"n1-standard-4\",\n",
    "        \"disk_config\": {\"boot_disk_type\": \"pd-standard\", \"boot_disk_size_gb\": 1024},\n",
    "    },\n",
    "    \"worker_config\": {\n",
    "        \"num_instances\": 2,\n",
    "        \"machine_type_uri\": \"n1-standard-4\",\n",
    "        \"disk_config\": {\"boot_disk_type\": \"pd-standard\", \"boot_disk_size_gb\": 1024},\n",
    "    },\n",
    "    \"lifecycle_config\": {\n",
    "        \"idle_delete_ttl\": Duration(seconds=3600)\n",
    "    }\n",
    "}\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'blent',\n",
    "    'start_date': days_ago(2),\n",
    "    'retries': 0,\n",
    "    'retry_delay': timedelta(minutes=10),\n",
    "    'project_id': Variable.get(\"PROJECT_ID\"),\n",
    "    'region': \"us-central1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous importons le module `dataproc_operator`, install√© via `pip`, qui va nous permettre d'interagir avec le service Dataproc de Google Cloud.\n",
    "\n",
    "Nous d√©finissons ensuite plusieurs variables.\n",
    "\n",
    "- `BUCKET`, qui est le nom du bucket o√π sont stock√©s les donn√©es, les fichiers de configuration, etc.\n",
    "- `CLUSTER_NAME_TEMPLATE`, qui est le mod√®le de nom qui sera attribu√© au cluster Dataproc que nous allons cr√©er.\n",
    "- `CLUSTER_CONFIG` qui va contenir les informations du cluster qui sera cr√©e.\n",
    "\n",
    "Notons dans le dictionnaire `default_args`, la pr√©sence des champs `project_id` et `region`. Ici, nous sp√©cifions au DAG entier le nom du projet Google Cloud, qui sera ensuite h√©rit√© pour chaque t√¢che : nous n'aurons donc pas besoin de re-sp√©cifier le nom du projet √† chaque instanciation de t√¢che. Cette variable doit √™tre pr√©sente en tant que variable sur Airflow.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines2.png\" />\n",
    "\n",
    "Nous pouvons ensuite sp√©cifier la cl√© de la variable ainsi que sa valeur.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines3.png\" />\n",
    "\n",
    "Elle sera ensuite automatiquement ajout√©e.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines4.png\" />\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Les variables seront <b>automatiquement crypt√©es</b> sur Airflow si elles contiennent le mot KEY ou SECRET.\n",
    "</div>\n",
    "\n",
    "Continuons ensuite la construction du DAG."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "python"
   },
   "source": [
    "with DAG(DAG_NAME, default_args=default_args, schedule_interval=\"0 5 * * 1\") as dag:\n",
    "\n",
    "    task_create_dataproc = DataprocCreateClusterOperator(\n",
    "        task_id='create_dataproc',\n",
    "        cluster_name=CLUSTER_NAME_TEMPLATE + \"{{ ds_nodash }}\",\n",
    "        region=\"us-central1\",  # Cela co√ªte moins cher en US central ;)\n",
    "        cluster_config=CLUSTER_CONFIG\n",
    "    )\n",
    "\n",
    "    task_delete_dataproc = DataprocDeleteClusterOperator(\n",
    "        task_id='delete_dataproc',\n",
    "        cluster_name=CLUSTER_NAME_TEMPLATE + \"{{ ds_nodash }}\",\n",
    "        trigger_rule=trigger_rule.TriggerRule.ALL_DONE,  # En cas d'erreur, on souhaite quand m√™me supprimer le cluster\n",
    "    )\n",
    "\n",
    "    task_create_dataproc.set_downstream(task_delete_dataproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La premi√®re t√¢che `task_create_dataproc` va d√©marrer un cluster Dataproc. Nous r√©-utilisons le mod√®le de nom auquel nous collons la date d'ex√©cution du DAG au format `YYYYMMDD` gr√¢ce √† la macro `{{ ds_nodash }}`. Ensuite nous pr√©cision la version de l'image Dataproc (Spark 3.2), et nous choisissons ensuite 2 machines avec `worker_config` (depuis `CLUSTER_CONFIG`) de type `n1-standard-4` (pareil pour la machine qui g√®re le cluster `master_config`). Pour les versions gratuites de GCP, on s√©lectionnera plut√¥t `n1-standard-1` ou `n1-standard-2` pour √©viter de d√©passer les quotas impos√©s.\n",
    "\n",
    "Tout comme nous l'avions fait sur l'interface, le param√®tre `idle_delete_ttl` fix√© √† 3600 indique que le cluster sera automatiquement d√©truit au bout de 1 heure (3600 secondes) si aucune t√¢che n'est en cours d'ex√©cution.\n",
    "\n",
    "La seconde t√¢che `task_delete_dataproc` va simplement supprimer le cluster cr√©er pr√©c√©demment. Attention toutefois, nous sp√©cifions la r√®gle de d√©clenchement `all_done`, qui signifie que m√™me si des t√¢ches parentes n'ont pas pu √™tre effectu√©s, on supprimera quand m√™me le cluster Dataproc pour √©viter de consommer des cr√©dits.\n",
    "\n",
    "Il ne reste plus qu'√† tester nos t√¢ches ... mais nous avons oubli√© l'authentification ! Heureusement, Airflow a pens√© √† tout et dispose de **connexions**.\n",
    "\n",
    "Les connexions (visibles dans la barre de navigation `Admin -> Connections`) permet d'√©tablir des connexions s√©curis√©s de mani√®re globale sans √† chaque fois re-d√©finir dans le code les m√©thodes d'authentification. Cela permet donc de faciliter la maintenance.\n",
    "\n",
    "√âditons la connexion nomm√©e `google_cloud_default` dans la liste des connexions.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Pour que le type de connexion Google Cloud apparaisse, il faut red√©marrer le <code>webserver</code> et le <code>scheduler</code>.\n",
    "</div>\n",
    "\n",
    "Pour cela, nous allons cr√©er un nouveau <a href=\"https://console.cloud.google.com/iam-admin/serviceaccounts\" target=\"_blank\">compte de service</a> sp√©cifique √† Airflow avec les autorisations suivantes.\n",
    "\n",
    "- Administrateur Dataproc\n",
    "- Utilisateur du compte de service\n",
    "- Lecteur des objets de l'espace de stockage\n",
    "- Lecteur de d√©p√¥t source\n",
    "- Compte de service Cloud Build\n",
    "\n",
    "Ce dernier r√¥le nous sera utile pour ex√©cuter Cloud Build √† partir d'un fichier YAML pr√©sent sur le bucket. Cr√©ons une nouvelle cl√© JSON et ins√©rons l√† dans Airflow (`Keyfile JSON`).\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines5.png\" />\n",
    "\n",
    "Maintenant que tout est configur√©, nous devrions voir notre DAG appara√Ætre avec les deux t√¢ches.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines6.png\" />\n",
    "\n",
    "Ouvrons dans un nouvel onglet <a href=\"https://console.cloud.google.com/dataproc/clusters\" target=\"_blank\">l'interface Dataproc</a> et essayons de tester notre premi√®re t√¢che."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "airflow tasks test pipeline_ml_staging create_dataproc 2021-01-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tout est correctement configur√©, nous pouvons voir le cluster appara√Ætre dans la r√©gion `us-central1`.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines7.png\" />\n",
    "\n",
    "Testons maintenant la t√¢che suivante pour supprimer le cluster."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "airflow tasks test pipeline_ml_staging delete_dataproc 2021-01-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons maintenant de glisser au milieu la t√¢che PySpark qui va transformer le jeu de donn√©es."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "python"
   },
   "source": [
    "from airflow.providers.google.cloud.operators.dataproc import (\n",
    "    DataprocCreateClusterOperator,\n",
    "    DataprocSubmitPySparkJobOperator,\n",
    "    DataprocDeleteClusterOperator\n",
    ")\n",
    "\n",
    "# ...\n",
    "\n",
    "with DAG(DAG_NAME, default_args=default_args, schedule_interval=\"0 5 * * 1\") as dag:\n",
    "\n",
    "    # ...\n",
    "\n",
    "    task_job = DataprocSubmitPySparkJobOperator(\n",
    "        task_id=\"submit_job\",\n",
    "        job_name=\"query_user_events\",\n",
    "        cluster_name=CLUSTER_NAME_TEMPLATE + \"{{ ds_nodash }}\",\n",
    "        main=\"gs://{}/scripts/create_events_data_file.py\".format(BUCKET),\n",
    "        dataproc_jars=[\"gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar\"],\n",
    "        arguments=[\"{{ ds }}\", \"{{ next_ds }}\"]\n",
    "    )\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    task_create_dataproc.set_downstream(task_job)\n",
    "    task_job.set_downstream(task_delete_dataproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'op√©rateur `DataprocSubmitPySparkJobOperator` va nous permettre d'envoyer une t√¢che PySpark au cluster sp√©cifi√© en y indiquant des param√®tres additionnels. En l'occurrence ici, nous ajoutons le JAR BigQuery car nous avons besoin de r√©cup√©rer les trajets pr√©sents sur BigQuery.\n",
    "\n",
    "Le param√®tre `argments` nous permet d'indiquer la fen√™tre temporelle sur laquelle nous allons r√©colter les donn√©es. Notons qu'ici nous choisissons l'intervalle de planification du DAG (qui correspond ici √† une semaine).\n",
    "\n",
    "N'oublions pas qu'Airflow ex√©cute **toujours un DAG √† la fin de sa p√©riode d'ex√©cution !** Ainsi, le DAG correspond au lundi 04 janvier 2021 √† 5h (valeur de `ds`) sera en r√©alit√© ex√©cut√© le lundi 11 janvier 2021 √† 5h. C'est pour cela que nous choisissons `next_ds` pour r√©colter les observations du 04/01 au 11/01, sinon nous aurions un d√©calage d'une semaine dans le pass√©.\n",
    "\n",
    "Testons alons avec un backfill."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "airflow dags backfill pipeline_ml_staging -s 2019-11-06 -e 2019-11-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec ce backfill, ce sera l'ex√©cution du lundi 11/11/2019 qui sera d√©clench√©e. Une fois le cluster en cours d'ex√©cution, nous pouvons voir la t√¢che PySpark envoy√© par Airflow.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines8.png\" />\n",
    "\n",
    "Cette t√¢che peut √™tre plus longue en terme d'ex√©cution puisque nous avons plus de donn√©es √† cette p√©riode par rapport √† d√©but octobre 2019. Si les temps de calcul sont trop longs, pour tester, nous pouvons r√©duire la taille de la fen√™tre.\n",
    "\n",
    "Une fois la t√¢che termin√©, nous devrions voir nos donn√©es toutes fra√Æches dans <a href=\"https://console.cloud.google.com/storage/browser\" target=\"_blank\">notre bucket</a>.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines9.png\" />\n",
    "\n",
    "Dans le m√™me temps, le cluster Dataproc est supprim√© par la derni√®re t√¢che Airflow.\n",
    "\n",
    "Il ne reste plus qu'√† ex√©cuter notre build via Cloud Build, et Kedro ira directement chercher ces fichiers CSV. Tout comme nous avions ex√©cut√© le build du `purchase-predict-api` √† partir du `cloudbuild.yaml` du projet `purchase-predict`, nous allons faire la m√™me chose ici avec l'op√©rateur `CloudBuildCreateBuildOperator`.\n",
    "\n",
    "Commen√ßons par importer cet op√©rateur."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "python"
   },
   "source": [
    "import secrets\n",
    "\n",
    "from airflow.providers.google.cloud.operators.cloud_build import (\n",
    "    CloudBuildCreateBuildOperator\n",
    ")\n",
    "\n",
    "CLOUD_BUILD_STEP_ARGS = \"\"\"\n",
    "gcloud source repos clone purchase_predict /tmp/purchase_predict --project=$PROJECT_ID\n",
    "git --git-dir=/tmp/purchase_predict/.git --work-tree=/tmp/purchase_predict checkout staging\n",
    "tar -C /tmp/purchase_predict -zcf /tmp/purchase_predict.tar.gz .\n",
    "gcloud builds submit \\\n",
    "--config /tmp/purchase_predict/cloudbuild.yaml /tmp/purchase_predict.tar.gz \\\n",
    "--substitutions SHORT_SHA=$SHORT_SHA,_MLFLOW_SERVER=$_MLFLOW_SERVER,BRANCH_NAME=staging\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `CLOUD_BUILD_STEP_ARGS` contient les arguments de la commande `bash` de l'√©tape qui va ex√©cuter un autre build depuis le d√©p√¥t `purchase-predict`. Notons ici que contrairement √† l'API, nous ne fournissons pas le dossier dans `gcloud builds submit` mais le contenu du dossier compress√©, car par d√©faut `gcloud builds submit` ne garde pas les sous-dossiers vides dont `conf/local` dans Kedro, alors que ce dernier en a besoin.\n",
    "\n",
    "Esuite, nous devons notamment y substituer des variables, dont le `SHORT_SHA` (qui sera g√©n√©r√© manuellement lors de l'appel de la t√¢che Airflow), l'adresse du serveur MLflow avec `_MLFLOW_SERVER` et enfin le nom de la branche Git (ici `staging`).\n",
    "\n",
    "Rajoutons la t√¢che dans le DAG et connectons-la avec les autres."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "python"
   },
   "source": [
    "with DAG(DAG_NAME, default_args=default_args, schedule_interval=\"0 5 * * 1\") as dag:\n",
    "\n",
    "    # ...\n",
    "\n",
    "    task_trigger_build = CloudBuildCreateBuildOperator(\n",
    "        task_id=\"trigger_ml_build\",\n",
    "        body={\n",
    "            \"steps\": [\n",
    "                {\n",
    "                    \"name\": \"gcr.io/google.com/cloudsdktool/cloud-sdk\",\n",
    "                    \"entrypoint\": \"bash\",\n",
    "                    \"args\": [\"-c\", CLOUD_BUILD_STEP_ARGS]\n",
    "                }\n",
    "            ],\n",
    "            \"timeout\": \"1800s\",\n",
    "            \"substitutions\": {\"_MLFLOW_SERVER\": Variable.get(\"MLFLOW_SERVER\"), \"SHORT_SHA\": str(secrets.token_hex(4))[:7]}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ...\n",
    "\n",
    "    task_create_dataproc.set_downstream(task_job)\n",
    "    # Il est conseill√© de mettre task_delete_dataproc avant task_trigger_build car cela supprimera le cluster avant s'il n'y a pas de parall√©lisme\n",
    "    task_job.set_downstream([task_delete_dataproc, task_trigger_build])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä l'instar du fichier `cloudbuild.yaml`, dans le param√®tre `body` de la t√¢che, nous d√©finissons les √©tapes du build. Ici, m√™me principe, il n'y a qu'une seule √©tape qui va elle-m√™me d√©clencher le build de `purchase-predict`.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines10.png\" />\n",
    "\n",
    "Avant d'ex√©cuter un backfill, rajoutons la variable `MLFLOW_SERVER` sur Airflow. Par ailleurs, il faut penser √† nettoyer les t√¢ches du DAG avant de faire le backfill, qui est consid√©r√© comme succ√®s, pour retester l'int√©gralit√© du DAG."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "airflow tasks clear pipeline_ml_staging -s 2019-11-06 -e 2019-11-13\n",
    "airflow dags backfill pipeline_ml_staging -s 2019-11-06 -e 2019-11-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    En comptabilisant le calcul Spark et tous les builds, cela peut prendre une trentaine de minutes. Pour ne pas √™tre bloqu√© par la limite de temps pour <code>purchase-predict</code>, on peut augmenter le <code>timeout</code> ou changer le type de machine pour ne obtenir une plus puissante.\n",
    "</div>\n",
    "\n",
    "Et apr√®s toute cette attente, nous allons finalement pouvoir profiter de la derni√®re version mise √† jour sur Cloud Run (car nous sommes dans l'environnement de pr√©-production).\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/airflow_pipelines11.png\" />\n",
    "\n",
    "Magique, non ? üò≤\n",
    "\n",
    "Il ne reste plus qu'√† faire le m√™me DAG mais pour l'environnement de production, qui bien entendu ne devrait pas poser de difficult√© car le d√©ploiement sur Kubernetes est g√©r√© par Cloud Build.\n",
    "\n",
    "En r√©sum√©, le fichier `pipeline_ml_production.py` est tr√®s proche de ce que nous venons de faire."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "download_as": "pipeline_ml_production.py",
    "format": "python"
   },
   "source": [
    "import os\n",
    "import secrets\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.models import Variable\n",
    "from airflow.utils.dates import days_ago\n",
    "from datetime import timedelta\n",
    "from google.protobuf.duration_pb2 import Duration\n",
    "\n",
    "from airflow.utils import trigger_rule\n",
    "from airflow.providers.google.cloud.operators.dataproc import (\n",
    "    DataprocCreateClusterOperator,\n",
    "    DataprocSubmitPySparkJobOperator,\n",
    "    DataprocDeleteClusterOperator\n",
    ")\n",
    "from airflow.providers.google.cloud.operators.cloud_build import (\n",
    "    CloudBuildCreateBuildOperator\n",
    ")\n",
    "\n",
    "DAG_NAME = os.path.basename(__file__).replace(\".py\", \"\")\n",
    "BUCKET = \"blent-formation-ml-engineer-data\"\n",
    "CLUSTER_NAME_TEMPLATE = \"purchase-predict-cluster-production-\"\n",
    "CLUSTER_CONFIG = {\n",
    "    \"software_config\": {\n",
    "        \"image_version\": \"2.0-debian10\"\n",
    "    },\n",
    "    \"master_config\": {\n",
    "        \"num_instances\": 1,\n",
    "        \"machine_type_uri\": \"n1-standard-4\",\n",
    "        \"disk_config\": {\"boot_disk_type\": \"pd-standard\", \"boot_disk_size_gb\": 1024},\n",
    "    },\n",
    "    \"worker_config\": {\n",
    "        \"num_instances\": 2,\n",
    "        \"machine_type_uri\": \"n1-standard-4\",\n",
    "        \"disk_config\": {\"boot_disk_type\": \"pd-standard\", \"boot_disk_size_gb\": 1024},\n",
    "    },\n",
    "    \"lifecycle_config\": {\n",
    "        \"idle_delete_ttl\": Duration(seconds=3600)\n",
    "    }\n",
    "}\n",
    "\n",
    "CLOUD_BUILD_STEP_ARGS = \"\"\"\n",
    "gcloud source repos clone purchase_predict /tmp/purchase_predict --project=$PROJECT_ID\n",
    "git --git-dir=/tmp/purchase_predict/.git --work-tree=/tmp/purchase_predict checkout master\n",
    "tar -C /tmp/purchase_predict -zcf /tmp/purchase_predict.tar.gz .\n",
    "gcloud builds submit \\\n",
    "--config /tmp/purchase_predict/cloudbuild.yaml /tmp/purchase_predict.tar.gz \\\n",
    "--substitutions SHORT_SHA=$SHORT_SHA,_MLFLOW_SERVER=$_MLFLOW_SERVER,BRANCH_NAME=master\n",
    "\"\"\"\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'blent',\n",
    "    'start_date': days_ago(2),\n",
    "    'retries': 0,\n",
    "    'retry_delay': timedelta(minutes=10),\n",
    "    'project_id': Variable.get(\"PROJECT_ID\"),\n",
    "    'region': \"us-central1\"\n",
    "}\n",
    "\n",
    "with DAG(DAG_NAME, default_args=default_args, schedule_interval=\"0 5 * * 1\") as dag:\n",
    "\n",
    "    task_create_dataproc = DataprocCreateClusterOperator(\n",
    "        task_id='create_dataproc',\n",
    "        cluster_name=CLUSTER_NAME_TEMPLATE + \"{{ ds_nodash }}\",\n",
    "        region=\"us-central1\",  # Cela co√ªte moins cher en US central ;)\n",
    "        cluster_config=CLUSTER_CONFIG\n",
    "    )\n",
    "\n",
    "    task_job = DataprocSubmitPySparkJobOperator(\n",
    "        task_id=\"submit_job\",\n",
    "        job_name=\"query_user_events\",\n",
    "        cluster_name=CLUSTER_NAME_TEMPLATE + \"{{ ds_nodash }}\",\n",
    "        main=\"gs://{}/scripts/create_events_data_file.py\".format(BUCKET),\n",
    "        dataproc_jars=[\"gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar\"],\n",
    "        arguments=[\"{{ ds }}\", \"{{ next_ds }}\"]\n",
    "    )\n",
    "\n",
    "    task_trigger_build = CloudBuildCreateBuildOperator(\n",
    "        task_id=\"trigger_ml_build\",\n",
    "        body={\n",
    "            \"steps\": [\n",
    "                {\n",
    "                    \"name\": \"gcr.io/google.com/cloudsdktool/cloud-sdk\",\n",
    "                    \"entrypoint\": \"bash\",\n",
    "                    \"args\": [\"-c\", CLOUD_BUILD_STEP_ARGS]\n",
    "                }\n",
    "            ],\n",
    "            \"timeout\": \"1800s\",\n",
    "            \"substitutions\": {\"_MLFLOW_SERVER\": Variable.get(\"MLFLOW_SERVER\"), \"SHORT_SHA\": str(secrets.token_hex(4))[:7]}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    task_delete_dataproc = DataprocDeleteClusterOperator(\n",
    "        task_id='delete_dataproc',\n",
    "        cluster_name=CLUSTER_NAME_TEMPLATE + \"{{ ds_nodash }}\",\n",
    "        trigger_rule=trigger_rule.TriggerRule.ALL_DONE,  # En cas d'erreur, on souhaite quand m√™me supprimer le cluster\n",
    "    )\n",
    "\n",
    "    task_create_dataproc.set_downstream(task_job)\n",
    "    # Il est conseill√© de mettre task_delete_dataproc avant task_trigger_build car cela supprimera le cluster avant s'il n'y a pas de parall√©lisme\n",
    "    task_job.set_downstream([task_delete_dataproc, task_trigger_build])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ùì Est-ce que l'on ne pourrait pas optimiser les deux DAGs ?\n",
    "\n",
    "Bien s√ªr ! Si l'on regarde en d√©tails, on r√©alise ici deux fois le m√™me calcul Spark. Nous pourrions par exemple fusionner sur un seul DAG, ou encore avoir un DAG qui fait le traitement Spark, puis ensuite d√©clencher les deux autres DAGs par la suite.\n",
    "\n",
    "Ici nous avons fait le choix de la flexibilit√© si, par exemple, on ne souhaiterai pas lancer les deux calculs en m√™me temps.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Dans le cadre de la formation, il faut faire attention √† v√©rifier que le cluster est bien supprim√© √† la fin. En effet, n'oublions pas qu'<i>in fine</i>, ce sont des ressources qui n√©cessitent des cr√©dits.\n",
    "</div>\n",
    "\n",
    "Pour terminer, on peut ensuite envoyer ce DAG dans Airflow sur le serveur (en pensant √† installer les d√©pendances suppl√©mentaires que nous avons fait au tout d√©but)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úîÔ∏è Conclusion\n",
    "\n",
    "Et voil√† ! Cela repr√©sente l'aboutissement de l'approche MLOps ! Tu peux √™tre tr√®s fier(e) de toi pour tout ce chemin parcouru ! ü•≥\n",
    "\n",
    "- Nous avons pu cr√©er et supprimer des clusters Dataproc depuis Airflow.\n",
    "- Nous avons ensuite int√©gr√© le d√©clenchement Cloud Build directement dans le DAG Airflow.\n",
    "\n",
    "> ‚û°Ô∏è Il y aurait encore tant de choses √† voir... mais pour terminer, il est important de voir quelques bonnes pratiques, notamment au niveau de la **s√©curit√©** ou encore du **monitoring** !"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "√âditer les M√©ta-Donn√©es",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
