{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "intro"
   },
   "source": [
    "Pour s'assurer qu'une fois en production, le mod√®le adopte un comportement similaire √† celui rencontr√© lors de la phase exp√©rimentale, nous devons utiliser des outils nous permettant de l'auditer. Bien que les scores permettent d'avoir une id√©e sur les performances globales, elles ne sont pas suffisantes.\n",
    "\n",
    "<blockquote><p>üôã <b>Ce que nous allons faire</b></p>\n",
    "<ul>\n",
    "    <li>√âvaluer les performances du mod√®le</li>\n",
    "    <li>Interp√©ter localement le mod√®le</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/uvoECTG2uCTrG/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du mod√®le\n",
    "\n",
    "Les premiers objectifs de la validation permettent de s'assurer que le mod√®le calibr√© respecte bien certaines contraintes qui ne sont pas uniquement li√©es aux performances ou au score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08e4aa853bb3747b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "model = joblib.load(os.path.expanduser(\"~/data/model.pkl\"))\n",
    "X_train = pd.read_csv(os.path.expanduser(\"~/data/X_train.csv\"))\n",
    "X_test = pd.read_csv(os.path.expanduser(\"~/data/X_test.csv\"))\n",
    "y_train = pd.read_csv(os.path.expanduser(\"~/data/y_train.csv\")).values.flatten()\n",
    "y_test = pd.read_csv(os.path.expanduser(\"~/data/y_test.csv\")).values.flatten()\n",
    "\n",
    "y_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densit√©s des classes\n",
    "\n",
    "Nous avons vu que la pr√©cision de notre mod√®le √©tait moins bonne que le rappel. En particulier, avec la courbe de calibration, nous avons pu observer que sur des probabilit√©s pr√©dites (classe positive) inf√©rieures √† $40\\%$, les proportions d'observations r√©ellement positives n'adoptaient pas un comportement lin√©aire.\n",
    "\n",
    "Pour mieux visualiser ce ph√©nom√®ne, il est courant de repr√©senter les densit√©s des deux classes sur un grahique. On affiche deux histogrammes, qui correspondent aux observations pr√©dites positivement et n√©gativement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a10c76b6f2cf4c9b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "sns.histplot(y_prob[y_test == 0, 1], alpha=0.5)\n",
    "plt.axvline(np.median(y_prob[y_test == 0, 1]), 0,1, linestyle=\"--\", label=\"Median Class 0\")\n",
    "plt.axvline(np.mean(y_prob[y_test == 0, 1]), 0,1, linestyle=\"-\", label=\"Mean Class 0\")\n",
    "\n",
    "sns.histplot(y_prob[y_test == 1, 1], color=\"darkorange\", alpha=0.4)\n",
    "plt.axvline(np.median(y_prob[y_test == 1, 1]), 0, 1, linestyle=\"--\", color=\"darkorange\", label=\"Median Class 1\")\n",
    "plt.axvline(np.mean(y_prob[y_test == 1, 1]), 0, 1, linestyle=\"-\", color=\"darkorange\", label=\"Mean Class 1\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Predicted probabilites\")\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.title(\"Density Chart\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel, nous avions d√©j√† calcul√© la courbe de calibration du mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de02d037b17ac5b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=20)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\", alpha=0.6)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Model\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.xlabel(\"Predicted probabilites\")\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que la courbe de calibration ne soit pas choquante, nous observons sur les densit√©s des classes que les deux distributions sont **asym√©triques** avec une moyenne √† gauche par rapport √† la m√©diane, traduisant d'un √©talement vers la gauche. Bien que ce soit attendu pour la classe positive, cela l'est moins pour la classe n√©gative. En effet, cette derni√®re devrait, pour un mod√®le parfait, √™tre √©tal√©e vers la droite, donc la majorit√© des observations sont √† gauche.\n",
    "\n",
    "En soit, ce graphe ne bloque pas la validation du mod√®le, elle traduit simplement de mani√®re visuelle que le mod√®le a plus de difficult√©s √† pr√©dire avec une forte confiance des probabilit√©s basses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbe ROC\n",
    "\n",
    "La courbe ROC trace la courbe de la sensibilit√© du mod√®le en fonction de sa sp√©cifit√©. En d'autres termes, il s'agit de tracer l'√©volution du taux de vrais positifs en fonction du taux de faux positifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0c0cd42ce034812"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:2.1f}%)'.format(auc(fpr, tpr) * 100))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.title(\"ROC Curve\", fontsize=16)\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###¬†Courbe PR\n",
    "\n",
    "Une autre courbe √©galement utilis√©e est la courbe PR, qui elle va tracer l'√©volution de la pr√©cision en fonction du rappel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cb1c1ec5f9cd9c5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict_proba(X_test)\n",
    "\n",
    "plt.figure(figsize=(16,11))\n",
    "prec, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1], pos_label=1)\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot(ax=plt.gca())\n",
    "plt.title(\"PR Curve\", fontsize=16)\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La principale diff√©rence entre les courbes ROC et PR, c'est que la pr√©cision et le rappel calculent des taux √† partir des vrais positifs sans se soucier des vrais n√©gatifs. La pr√©cision ne fait pas intervenir \n",
    "\n",
    "√Ä l'inverse de la courbe ROC, la pr√©cision n'utilise pas le TPR, mais la PPV !\n",
    "\n",
    "√Ä l'inverse, la courbe ROC utilise toutes les informations.\n",
    "\n",
    "Si l'on ne s'int√©resse pas √† la **sp√©cificit√©**, alors la courbe PR peut √™tre int√©ressante √† interpr√©ter. Dans le cas contraire, la courbe ROC pourra fournir plus d'informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "break": "new"
   },
   "source": [
    "## Interpr√©tation locale\n",
    "\n",
    "Au cours des derni√®res ann√©es, les mod√®les de Machine Learning atteignaient des performances de plus en plus √©lev√©es, d√©passant parfois les performances r√©alis√©es par des humains sur certaines t√¢ches pr√©cises. La comp√©tition annuelle ILSVRC, o√π des √©quipes de recherche √©valuent des algorithmes de traitement d'image sur le jeu de donn√©es ImageNet, voyait les meilleurs taux d'erreurs √† $26\\%$. \n",
    "\n",
    "En 2012, l'av√®nement des r√©seaux de neurones et de l'apprentissage profond, et plus particuli√®rement les r√©seaux de neurones convolutifs ont permis d'abaisser le taux d'erreur √† $16\\%$. Depuis, les r√©seaux de neurones sont majoritairement utilis√©s dans cette comp√©tition et d'autres semblables.\n",
    "\n",
    "<img src=\"https://dv495y1g0kef5.cloudfront.net/training/data_scientist_airbnb/img/interp1.png\" />\n",
    "\n",
    "En contrepartie, les r√©seaux de neurones sont souvent consid√©r√©s comme des ¬´ bo√Ætes noires ¬ª, c'est-√†-dire des algorithmes dont le fonctionnement est opaque et difficile √† interpr√©ter. En effet, du fait du tr√®s grand nombre de param√®tres (plusieurs dizaines voir centaines de millions), l'interpr√©tation de ces mod√®les n'est pas faisable.\n",
    "\n",
    "Les r√©seaux de neurones sont un exemple de ¬´ bo√Ætes noires ¬ª, tout comme le sont les algorithmes d'ensemble learning que nous avons construit tels que Random Forest ou XGBoost.\n",
    "\n",
    "Le terme **transparence des algorithmes** est propre au contexte √©tudi√©, et il n'existe pas une d√©finition unique. La transparence peut faire r√©f√©rence √† la connaissance de la d√©cision prise par l'algorithme, au degr√© d'exactitude de la pr√©diction ou √† l'importance des variables sur la pr√©diction.\n",
    "\n",
    "<a href=\"https://christophm.github.io/interpretable-ml-book/\" target=\"_blank\">Christoph Molnar</a> reprend la d√©finition de l'interpr√©tabilit√© de Tim Miller :\n",
    "\n",
    "<p style=\"text-align: center;\">¬´ L'interpr√©tabilit√© est le degr√© √† quel point un humain peut expliquer de mani√®re coh√©rente les pr√©dictions du mod√®le ¬ª</p>\n",
    "\n",
    "Sous cette d√©finition, l'interpr√©tabilit√© est une partie int√©grante de la transparence, qui vise √† √™tre capable d'expliquer de mani√®re pr√©cise et consistante la pr√©diction, que ce soit pour une observation ou dans le comportement global de l'algorithme.\n",
    "\n",
    "### Mod√®les naturellement interpr√©tables\n",
    "\n",
    "Que signifie un mod√®le naturellement interpr√©table ? Lorsque nous avons r√©alis√© la r√©gression lin√©aire, nous avons √©t√© capable de calculer directement l'impact de chaque variable sur la pr√©diction. De plus, du fait de l'hypoth√®se de lin√©arit√© entre les variables, il est facile d'expliquer comment, **pour un individu donn√©, le r√©sultat a √©t√© obtenu (i.e. de combien le prix a augment√© ou diminu√©)**. Enfin, le mod√®le suppose initialement **l'ind√©pendance entre les variables**, ce qui permet de consid√©rer les effets crois√©s entre les variables inexistants.\n",
    "\n",
    "$$y_i= \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} + \\varepsilon_i$$\n",
    "\n",
    "Autrement dit, chaque variable **est associ√©e d'un \"poids\" $\\beta_j$** : dans le cas o√π toutes les variables sont dans la m√™me unit√© de mesure, cela permet donc de mesure **l'importance de chaque variable**.\n",
    "\n",
    "N√©anmoins, chaque individu poss√®de des caract√©ristiques diff√©rentes : et c'est notamment en multipliant la valeur $x_{ij}$ d'une variable d'un individu $x_i$ par le poids $\\beta_j$ que l'on peut caract√©riser, **pour cet individu**, l'importance et le r√¥le de la variable sur la pr√©diction.\n",
    "\n",
    "En revanche, les mod√®les qui permettent d'atteindre des performances plus √©lev√©es, sont √©galement plus difficilement interpr√©tables. Le mod√®le XGBoost est construit de mani√®re r√©cursive, et chaque arbre d√©pends des pr√©c√©dents. Pour expliquer la pr√©diction d'une observation $x$, il est n√©cessaire de calculer la sortie de chaque arbre, en sachant que les pr√©dicteurs faibles ne cherchent plus √† mod√©liser la variable r√©ponse, mais les pseudo-r√©sidus. C'est la multiplicit√© des arbres (associ√©e √† d'√©ventuels arbres profonds) qui rend la compr√©hension du comportement du mod√®le quasi-impossible.\n",
    "\n",
    "Ainsi, au cours des derni√®res ann√©es, la recherche acad√©mique s'est pench√©e sur des m√©thodes d'interpr√©tabilit√© afin de pouvoir expliquer le comportement et les pr√©dictions des algorithmes. Deux types de m√©thodes ont √©t√© d√©velopp√©es.\n",
    "\n",
    "### M√©thode agnostiques\n",
    "\n",
    "Les m√©thodes dites **agnostiques** sont ind√©pendantes du mod√®le pr√©dictif utilis√©. Le principal avantage est leur flexibilit√©, puisque ces m√©thodes peuvent √™tre appliqu√©es sans connaissance particuli√®re du mod√®le pr√©dictif, si ce n'est qu'obtenir la pr√©diction $\\hat{f}(\\mathbf{x})$ pour toute observation $\\mathbf{x}$. Ces m√©thodes agnostiques s'intercalent sur des mod√®les bo√Ætes noires. Les PDP (Partial Dependency Plot) furent une des premi√®res m√©thodes d'interpr√©tabilit√©, en estimant les lois marginales des variables sous des hypoth√®ses d'ind√©pendance entre les variables. Plus r√©cemment, d'autres m√©thodes telles que **LIME** ou **Kernel SHAP** ont √©t√© introduites afin de pallier certaines faiblesses des pr√©c√©dentes m√©thodes et de les adapter pour des mod√®les plus complexes et plus co√ªteux en terme de calcul.\n",
    "\n",
    "### M√©thode sp√©cifiques\n",
    "\n",
    "Les m√©thodes dites **sp√©cifiques** d√©pendent du mod√®le pr√©dictif utilis√©. Bien que ces m√©thodes soient moins flexibles, elles permettent d'obtenir de meilleurs interpr√©tabilit√© puisqu'elles sont sp√©cifiquement d√©velopp√©es pour un mod√®le pr√©dictif particulier. Ces m√©thodes ne se reposent pas uniquement sur la pr√©diction $\\hat{f}(\\mathbf{x})$ des observations $\\mathbf{x}$, mais utilisent √©galement les propri√©t√©s et m√©thodes de construction d'un mod√®le pour en extraire le plus d'information quant au comportement que celui-ci adopte. Les r√©seaux de neurones sont principalement vis√©s par ces m√©thodes avec **DeepLIFT**, ou les mod√®les √† base d'arbres avec **Tree SHAP**.\n",
    "\n",
    "### Niveaux de granularit√©\n",
    "\n",
    "Lorsque le terme d'interpr√©tabilit√© est employ√©, deux niveaux de granularit√© peuvent √™tre distingu√©s en classes de m√©thodes.\n",
    "\n",
    "- Les m√©thodes dites **locales**, o√π la m√©thode consiste √† expliquer la pr√©diction d'une observation particuli√®re. Christoph Molnar diff√©rencie l'interpr√©tabilit√© (g√©n√©rale) du mod√®le et appelle l'*explication* le fait de pouvoir pleinement expliquer la pr√©diction pour une observation particuli√®re. DeepLIFT ou Tree SHAP sont des exemples de m√©thodes locales.\n",
    "- Les m√©thodes dites **globales**, qui cherchent plut√¥t √† expliquer les tendances du mod√®le sur l'ensemble des pr√©dictions, comme par exemple les lois marginales. PDP ou Tree Interpreter sont des exemples de m√©thodes globales.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Ces m√©thodes calculent souvent une approximation pour pouvoir interpr√©ter plus facilement : <b>attention √† la sur-interpr√©tation</b>.\n",
    "</div>\n",
    "    \n",
    "Nous allons nous concentrer ici √† **l'interpr√©tabilit√© locale** du mod√®le.\n",
    "\n",
    "## Valeurs de Shapley\n",
    "\n",
    "Les valeurs de Shapley fournissent une m√©thode d'interpr√©tabilit√© **locale** : elles permettent de r√©pondre √† la question ¬´ pourquoi cet utilisateur a une forte probabilit√© d'acheter ? ¬ª. Faisons une petite introduction √† cette m√©thode.\n",
    "\n",
    "Les valeurs de Shapley puisent leurs origines dans la th√©orie des jeux coop√©ratifs. Ces valeurs furent calcul√©es par Lloyd Shapley en 1953. Les valeurs de Shapley indiquent la r√©partition √©quitable des gains parmi les joueurs (ou *acteurs*) d'une coalition dans le cadre d'un jeu coop√©ratif. Cette configuration induit une **utilit√© transf√©rable**, puisque l'objectif de cette coalition est de **maximiser** le profit global, pour ensuite redistribuer ce montant parmi les membres de la coalition. Il est important de distinguer la notion d'√©quit√© et d'√©galit√©. Soient trois joueurs $A, B$ et $C$ qui, individuellement, n'apportent aucun gain, mais qui, sous forme de coalition, apportent les gains suivants :\n",
    "\n",
    "- la coalition $\\{A, B\\}$ rapporte $2$ ;\n",
    "- la coalition $\\{A, C\\}$ rapporte $2$ ;\n",
    "- la coalition $\\{B, C\\}$ rapporte $3$ ;\n",
    "- la coalition totale $\\{A, B, C\\}$ rapporte le gain total $4$.\n",
    "\n",
    "Dans cet exemple, il est clair que la coalition $\\{B, C\\}$ est celle qui **contribue** le plus au gain total par rapport aux autres coalitions. Ainsi, pour satisfaire une notion d'√©quit√©, les joueurs de la coalition $\\{B, C\\}$ doivent recevoir une part plus importante du gain total par rapport au joueur $A$.\n",
    "\n",
    "Pour un jeu coop√©ratif √† $p$ joueurs, il peut y avoir $2^p-1$ coalitions non vides possibles, o√π chaque joueur est identifi√© par un indice allant de $1$ √† $p$. Le profit **est suppos√© connu** pour chaque partie de $\\{1,‚Ä¶,p\\}$, et se quantifie par la **fonction caract√©ristique** $v:\\mathcal{P}(\\{1,‚Ä¶,p\\}) \\rightarrow \\mathbb{R}$, et v√©rifiant $v(\\emptyset)=0$. En pratique, rien ne suppose que les gains d'une coalition soient toujours sup√©rieurs √† la somme des gains de chaque joueur, soit\n",
    "\n",
    "$$v \\left( \\bigcup_i \\{i\\} \\right) \\ngeqslant \\sum_{i} v(\\{i\\})$$\n",
    "\n",
    "Dans ce cas de figure, un ou plusieurs joueurs auront une valeur de Shapley **inf√©rieure** au gain individuel, car ils contribueront √† faire baisser les gains lors du rassemblement en coalition. Cet √©v√©nement peut survenir dans des cadres classiques de la th√©orie moderne de l'√©conomie (deux entreprises qui coop√®rent ensemble peuvent obtenir un profit moins √©lev√© que si elles ne coop√©raient pas), mais cet aspect est particuli√®rement important en apprentissage supervis√©, ce qui sera d√©taill√© par la suite.\n",
    "\n",
    "Shapley a donc d√©termin√© la seule solution qui v√©rifie ces axiomes, √† savoir\n",
    "\n",
    "$$\\phi_i=\\sum_{Z \\subseteq\\{1, \\dots, p\\} : j \\in Z} \\frac{(p-|Z|)!(|Z|-1)!}{p!}\\left [ v(Z)-v(Z \\backslash \\{ j\\}) \\right ]$$\n",
    "\n",
    "o√π $|Z|$ d√©signe la cardinalit√© de l'ensemble $Z$. Cette formule op√®re comme d√©finition des valeurs de Shapley que nous utiliserons dans la mod√©lisation. Notons que le calcul des valeurs de Shapley implique de **conna√Ætre les gains pour toutes les coalitions possibles**. Dans certains domaines (√©conomique par exemple), cela n'est pas toujours possible, notamment lorsque les coalitions ne peuvent pas se reformer (si deux entreprises coop√®rent, leurs gains individuels apr√®s coop√©ration peuvent √™tre diff√©rents des gains individuels avant coop√©ration). Ainsi, $v$ est **enti√®rement d√©termin√©e** et pour tout $C \\subseteq \\{1, \\dots, p\\}$, la valeur $v(C)$ est connue.\n",
    "\n",
    "### SHAP\n",
    "\n",
    "En 2017, Scott Lundberg propose SHAP comme mesure unifi√©e de l'importance des variables. Son id√©e est la suivante :\n",
    "\n",
    "- On consid√®re que les variables sont **les joueurs**.\n",
    "- La coalition totale repr√©sente l'ensemble des variables, et le gain correspond √† **la pr√©diction du mod√®le**\n",
    "\n",
    "Id√©alement, une valeur de Shapley pour une variable nous indiquerait quelle est sa contribution sur la pr√©diction. Par exemple, une valeur de Shapley proche de $0$ signifierait que la variable n'a pas beaucoup impact√© la pr√©diction, alors qu'une valeur √©lev√©e indiquerait que la variable impacte fortement le prix du logement.\n",
    "\n",
    "Avec SHAP, nous allons pouvoir calculer ces valeurs de Shapley (de mani√®re approximative ou exacte pour les arbres de d√©cision).\n",
    "\n",
    "Ainsi, Lundberg a montr√© que, pour chaque individu x, les valeurs SHAP sont calcul√©es de sorte √† exprimer la pr√©diction $\\hat{f}(\\mathbf{x})$ par la somme des contributions des variables :\n",
    "\n",
    "$$\\hat{f}(\\mathbf{x})=\\frac{1}{1+\\exp \\left(-\\phi_0-\\sum_{j=1}^p \\phi_j \\right)}$$\n",
    "\n",
    "Avec $\\phi_0$ la moyenne des valeurs de Shapley pour la classe positive. Les valeurs de Shapley vont √™tre stock√©es dans la variable `shap_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42381a542e948c39"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# L'objet Explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "X_shap = X_test.copy()\n",
    "# On r√©cup√®re les valeurs de Shapley dans la matrice (pour la proba positive)\n",
    "shap_values = explainer.shap_values(X_shap)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour interpr√©ter plus facilement les valeurs de Shapley d'une observation, nous allons d√©composer chaque variable sur un diagramme en b√¢tons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f5dd5254ad88922"
   },
   "outputs": [],
   "source": [
    "# Cette fonction permet d'afficher les valeurs de Shapley sous forme de diagramme en b√¢tons\n",
    "def plot_shapley_values(index):\n",
    "    shap_df = pd.DataFrame.from_dict({\n",
    "        'Variable': X_shap.columns + \" (\" + X_shap.iloc[0, :].values.astype(str) + \")\",\n",
    "        'Valeur de Shapley': shap_values[index, :]\n",
    "    })\n",
    "\n",
    "    # Pour rappel, la pr√©diction est √©gale √† la somme des valeurs de Shapley + la valeur moyenne\n",
    "    prob = explainer.expected_value[1] + shap_df['Valeur de Shapley'].sum()\n",
    "    prob = 1 / (1 + np.exp(-prob))\n",
    "\n",
    "    plt.figure(figsize=(13,10))\n",
    "    sns.barplot(\n",
    "        y='Variable',\n",
    "        x='Valeur de Shapley',\n",
    "        data=shap_df.sort_values('Valeur de Shapley', ascending=False)\n",
    "    )\n",
    "    plt.title(\n",
    "        \"Probabilit√© : {:2.2f}%\".format(prob * 100),\n",
    "        fontsize=18\n",
    "    )\n",
    "    plt.yticks(fontsize=13)\n",
    "    \n",
    "plot_shapley_values(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce logement, le mod√®le est ind√©cis puisqu'il pr√©dit presque $50/50$. Ce que l'on remarque, c'est que pour cet utilisateur, ce produit en particulier contribue fortement √† faire baisser la probabilit√©.\n",
    "\n",
    "Prenons un autre utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68cc0a69742c5e37"
   },
   "outputs": [],
   "source": [
    "plot_shapley_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revanche, pour cet utilisateur, il y a une tr√®s forte probabilit√© d'achat. Les variables les plus impactantes sont le nombre de vues et de sessions.\n",
    "\n",
    "Dans certains cas, il est possible d'interpr√©ter globalement en affichant les valeurs de Shapley de chaque variable et de chaque observation. La variation de couleur indique si la variable a une grande valeur ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe1ae9c80d3dbe3f"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_shap, plot_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors que l'on observe une tendance croissante pour le `num_views_session` ou `duration`, cela est plus difficile pour `product_id`, `brand` ou `category`, ce qui est pr√©visible puisque nous avions r√©alis√© un encodage par dictionnaire : il n'y a donc pas de relation d'ordre entre les variables.\n",
    "\n",
    "Regardons en d√©tail les valeurs de Shapley uniquement pour la variable `product_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ed99ef8a4802fac"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"product_id\", shap_values, X_shap, interaction_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est int√©ressant de voir que certains paliers se forment : sp√©cifiquement entre 2e7 et 3e7, il y a certains produits qui influencent positivement la probabilit√© d'acheter, car leur valeurs s'√©l√®vent √† $4$.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    La valeur de Shapley ne repr√©sente pas une probabilit√© ! Il s'agit du calcul avant le passage par la fonction logistique.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f770a233ea5eb6f8"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"hour\", shap_values, X_shap, interaction_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'heure de visite, nous observons √©galement un comportement moyen d√©croissant entre 5h et 17h, puis une augmentation jusqu'√† 00h. Cette baisse peut s'expliquer par le fait qu'√† partir de 17h, il y a beaucoup plus de connexions qu'en milieu de nuit, et que ces utilisateurs sont plus souvent ind√©cis que ceux visitant le site la nuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06cef181c58231a3"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"num_views_session\", shap_values, X_shap, interaction_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrairement √† ce que nous pourrions penser, les valeurs de Shapley sont √©lev√©es pour les faibles valeurs de `num_views_sessions`. √Ä partir de $5$ visites dans la m√™me session, les valeurs de Shapley sont plus diffuses mais sont en moyenne de l'ordre de $-0.5$, faisant ainsi l√©g√®rement baisser la probabilit√©.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Il faut toujours garder en t√™te qu'il y a des interactions entre les variables, et que le fait d'avoir des valeurs de Shapley √©lev√©es pour de faibles valeurs ne peut pas se r√©sum√©rer √† cette seule variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "ending"
   },
   "source": [
    "## ‚úîÔ∏è Conclusion\n",
    "\n",
    "Cette √©tape de validation est importante, puisque lorsque nous automatiserons l'entra√Ænement du mod√®le, seuls ces graphiques et ces interpr√©tations permettront de v√©rifier que le mod√®le est r√©ellement performant, et pas uniquement en terme de m√©triques.\n",
    "\n",
    "- Nous avons valid√© le mod√®le √† l'aide de graphiques.\n",
    "- Nous avons interpr√©t√© localement certaines observations avec les valeurs de Shapley.\n",
    "\n",
    "> ‚û°Ô∏è Maintenant que avons construit notre pipeline ML, de la transformation des donn√©es √† la validation, il nous faut l'appliquer non pas sur un √©chantillon d'un jour d'historique, mais de $7$ jours d'historique."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "√âditer les M√©ta-Donn√©es",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
