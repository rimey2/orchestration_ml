{"cells": [{"cell_type": "markdown", "metadata": {"type": "intro"}, "source": ["Pour le pipeline de pr\u00e9-production, l'API est d\u00e9ploy\u00e9 sur Cloud Run et est ex\u00e9cut\u00e9 dans un conteneur Docker. Le **pipeline de production**, qui est suppos\u00e9 servir des dizaines de requ\u00eates par seconde, doit quant \u00e0 lui \u00eatre ex\u00e9cut\u00e9 sur Kubernetes pour impl\u00e9menter la scalabilit\u00e9.\n", "\n", "Le pipeline de production que nous allons construire ira, \u00e0 terme, d\u00e9ployer l'API directement dans Kubernetes. Il nous faut donc construire les fichiers de configuration du Deployment qui permettra d'ex\u00e9cuter l'API.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod6.png\" />\n", "\n", "Dans ce Notebook, il est question de mettre en place cette partie sp\u00e9cifique du d\u00e9ploiement dans le pipeline de production.\n", "\n", "<blockquote><p>\ud83d\ude4b <b>Ce que nous allons faire</b></p>\n", "<ul>\n", "    <li>Cr\u00e9er et configurer un cluster K8s pour l'API de production</li>\n", "    <li>D\u00e9finir les fichiers de configuration YAML</li>\n", "    <li>D\u00e9livrer automatiquement l'API via un d\u00e9clencheur</li>\n", "</ul>\n", "</blockquote>\n", "\n", "<img src=\"https://media.giphy.com/media/ToMjGpwbnkdSSSp0VnW/giphy.gif\" />"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Configuration du cluster K8s\n", "\n", "Pour exposer l'API via un cluster K8s, nous allons en configurer un nouveau que nous appelerons `purchase-predict-api`.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod1.png\" />\n", "\n", "Nous allons ensuite configurer le pool de noeuds par d\u00e9faut. Nous allons activer l'autoscaling avec un intervalle de noeuds situ\u00e9 entre 1 et 5. Au total, le cluster ne pourra pas exc\u00e9der de 5 noeuds.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod2.png\" />\n", "\n", "Concernant les types de machines, nous pouvons garder les `e2-medium`.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod3.png\" />\n", "\n", "Puisque nous sommes limit\u00e9 \u00e0 5 noeuds en autoscaling, nous pourrons avoir au total 10 CPU et 10 Go. Nous affectons \u00e0 chaque noeud 10Go d'espace disque, ce qui sera amplement suffisant puisqu'il n'y a pas de stockage local.\n", "\n", "Une fois le cluster lanc\u00e9, nous pouvons nous y connecter via la commande `gcloud`.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod4.png\" />\n", "\n", "### Espaces de noms\n", "\n", "En pratique, il se peut que les clusters K8s ne contiennent pas un seul mais plusieurs applications. Dans ce genre de situation, une bonne pratique consiste \u00e0 segmenter les ressources pr\u00e9sentes \u00e0 l'aide d'espaces de noms (*namespaces*). Ces espaces de noms fournissent des isolations logiques entre les ressources. Les services d'un espace de nom ne pourra \u00eatre associ\u00e9 \u00e0 des pods d'un autre service.\n", "\n", "Par d\u00e9faut, il y a 4 espaces de noms pr\u00e9sents dans le cluster."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["kubectl get ns"]}, {"cell_type": "raw", "metadata": {"format": "console"}, "source": ["NAME              STATUS   AGE\n", "default           Active   2m33s\n", "kube-node-lease   Active   2m34s\n", "kube-public       Active   2m35s\n", "kube-system       Active   2m35s"]}, {"cell_type": "markdown", "metadata": {}, "source": ["L'espace de noms `default` est celui utilis\u00e9 par d\u00e9faut lorsque l'on ne sp\u00e9cifie pas d'espaces de noms pour les ressources. Les autres espaces de noms `kube-*` sont utilis\u00e9s par le cluster lui-m\u00eame.\n", "\n", "<div class=\"alert alert-block alert-info\">\n", "    Il faut \u00e9viter d'utiliser des espaces de noms avec <code>kube</code> comme pr\u00e9fixe, car ils sont r\u00e9serv\u00e9s au cluster.\n", "</div>\n", "\n", "Cr\u00e9ons le fichier `ns.yaml` qui va nous permettre de d\u00e9finir un espace de noms."]}, {"cell_type": "raw", "metadata": {"format": "yaml"}, "source": ["apiVersion: v1\n", "kind: Namespace\n", "metadata:\n", "  name: api-purchase"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comme toujours, pour cr\u00e9er la ressource, nous utilisons `kubectl apply`."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["kubectl apply -f ns.yaml"]}, {"cell_type": "markdown", "metadata": {}, "source": ["L'espace de noms \u00e9tant cr\u00e9\u00e9, nous pouvons le d\u00e9tailler."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["kubectl describe ns api-purchase"]}, {"cell_type": "raw", "metadata": {"format": "console"}, "source": ["Name:         api-purchase\n", "Labels:       <none>\n", "Annotations:  <none>\n", "Status:       Active\n", "\n", "Resource Quotas\n", " Name:                       gke-resource-quotas\n", " Resource                    Used  Hard\n", " --------                    ---   ---\n", " count/ingresses.extensions  0     100\n", " count/jobs.batch            0     5k\n", " pods                        0     1500\n", " services                    0     500\n", "\n", "No LimitRange resource."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Les quotas appliqu\u00e9s sont ceux configur\u00e9s par d\u00e9faut dans GKE. Il est bien entendu possible de modifier ces valeurs dans la configuration du cluster, mais elles seront amplement suffisantes pour l'API.\n", "\n", "La configuration du cluster K8s est termin\u00e9e, nous pouvons maintenant nous atteler aux fichiers de configurations."]}, {"cell_type": "markdown", "metadata": {"break": "new"}, "source": ["## Fichiers de configuration YAML\n", "\n", "Avant de commencer, assurons-nous d'\u00eatre sur **la bonne branche** Git ! Le fichier `cloudbuild.yaml` qui nous avions configur\u00e9 \u00e9tait valide pour la pr\u00e9-production, mais ne sera plus identique pour la production.\n", "\n", "Pour cela, nous allons retourner sur la branche `master` et **fusionner** avec la branche `staging`."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["git checkout master\n", "git merge staging"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cr\u00e9ons un dossier `k8s/` \u00e0 la racine du projet : nous allons y ins\u00e9rer tous les fichiers de configuration YAML qui seront utilis\u00e9s avec `kubectl`. Commen\u00e7ons par le fichier `deployment.yaml`."]}, {"cell_type": "raw", "metadata": {"download_as": "deployment.yaml", "format": "yaml"}, "source": ["apiVersion: apps/v1\n", "kind: Deployment\n", "metadata:\n", "  name: purchase-predict\n", "  labels:\n", "    app: purchase-predict\n", "spec:\n", "  replicas: 2\n", "  selector:\n", "    matchLabels:\n", "      app: pod-purchase-predict\n", "  template:\n", "    metadata:\n", "      labels:\n", "        app: pod-purchase-predict\n", "    spec:\n", "      containers:\n", "      - name: pod-purchase-predict\n", "        image: gcr.io/training-ml-engineer/purchase-predict-api\n", "        env:\n", "        - name: PORT\n", "          value: \"80\"\n", "        - name: ENV\n", "          value: \"staging\"\n", "        - name: MLFLOW_SERVER\n", "          value: \"http://34.107.0.37/\"\n", "        - name: MLFLOW_REGISTRY_NAME\n", "          value: \"purchase_predict\"\n", "        ports:\n", "        - containerPort: 80\n", "        resources:\n", "          requests:\n", "            memory: \"0.5G\"\n", "            cpu: \"0.5\"\n", "          limits:\n", "            memory: \"1G\"\n", "            cpu: \"1\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["La configuration du Deployment est tr\u00e8s similaire \u00e0 celui que nous avions d\u00e9j\u00e0 r\u00e9alis\u00e9, \u00e0 la seule diff\u00e9rence que nous avons modifi\u00e9 l'image Docker, les ressources et des variables d'environnement n\u00e9cessaires pour l'ex\u00e9cution de l'API. L'image Docker correspond ici au tag le plus r\u00e9cent.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod5.png\" />\n", "\n", "Ajoutons le Deployment dans le cluster."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["kubectl apply --namespace api-purchase -f k8s/deployment.yaml"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En faisant un `kubectl get pods`, nous voyons qu'il n'y a aucune ressource ! En effet, sans mention particuli\u00e8re, `kubectl` ira toujours chercher les ressources de l'espace de noms `default`. Il faut donc le sp\u00e9cifier pour acc\u00e9der aux ressources."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["kubectl get pods --namespace api-purchase"]}, {"cell_type": "raw", "metadata": {"format": "console"}, "source": ["NAME                                READY   STATUS    RESTARTS   AGE\n", "purchase-predict-675fc5db9d-bl65d   1/1     Running   0          80s\n", "purchase-predict-675fc5db9d-jmbph   1/1     Running   0          80s"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-info\">\n", "    Il se peut que le cluster proc\u00e8de \u00e0 de l'autoscaling : le deuxi\u00e8me pod prendrai plus de temps \u00e0 d\u00e9marrer.\n", "</div>\n", "\n", "Maintenant que nos pods sont en place, cr\u00e9ons le service associ\u00e9 dans le fichier `service.yaml`."]}, {"cell_type": "raw", "metadata": {"download_as": "service.yaml", "format": "yaml"}, "source": ["apiVersion: v1\n", "kind: Service\n", "metadata:\n", "  name: purchase-predict-service\n", "spec:\n", "  type: NodePort\n", "  ports:\n", "    - port: 80\n", "      targetPort: 80\n", "  selector:\n", "    app: pod-purchase-predict"]}, {"cell_type": "raw", "metadata": {}, "source": ["kubectl apply --namespace api-purchase -f k8s/service.yaml"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pour terminer, nous allons placer un Ingress en frontal."]}, {"cell_type": "raw", "metadata": {"download_as": "ingress.yaml", "format": "yaml"}, "source": ["apiVersion: networking.k8s.io/v1beta1\n", "kind: Ingress\n", "metadata:\n", "  name: app-ingress\n", "spec:\n", "  rules:\n", "  - http:\n", "      paths:\n", "      - path: /*\n", "        backend:\n", "          serviceName: purchase-predict-service\n", "          servicePort: 80"]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["kubectl apply -f k8s/ingress.yaml --namespace api-purchase"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comme nous l'avions fait pr\u00e9c\u00e9demment, l'Ingress est en cours de cr\u00e9ation comme nous pouvons le voir avec `kubectl get ingress app-ingress --namespace api-purchase`."]}, {"cell_type": "raw", "metadata": {"format": "console"}, "source": ["Name:             app-ingress\n", "Namespace:        api-purchase\n", "Address:          \n", "Default backend:  default-http-backend:80 (10.108.1.5:8080)\n", "Rules:\n", "  Host        Path  Backends\n", "  ----        ----  --------\n", "  *           \n", "              /*   purchase-predict-service:80 (10.108.0.2:80,10.108.1.6:80)\n", "Annotations:  <none>\n", "Events:\n", "  Type    Reason  Age                From                     Message\n", "  ----    ------  ----               ----                     -------\n", "  Normal  Sync    45s (x2 over 45s)  loadbalancer-controller  Scheduled for sync\n", "  Normal  Sync    7s                 loadbalancer-controller  UrlMap \"k8s2-um-efrpzb5i-api-purchase-app-ingress-f9i0pcz7\" created\n", "  Normal  Sync    4s                 loadbalancer-controller  TargetProxy \"k8s2-tp-efrpzb5i-api-purchase-app-ingress-f9i0pcz7\" created"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Il faut patienter quelques minutes le temps que Google provisionne un \u00e9quilibreur de charge et qu'il soit enti\u00e8rement configur\u00e9. Ensuite, nous pouvons requ\u00eater \u00e0 l'adresse renseign\u00e9e par l'Ingress via `kubectl get ingress --namespace api-purchase`."]}, {"cell_type": "raw", "metadata": {"format": "console"}, "source": ["NAME          HOSTS   ADDRESS         PORTS   AGE\n", "app-ingress   *       34.117.133.85   80      10m"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Maintenant que toutes nos ressources sont en place, ex\u00e9cutons le code Python suivant."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "7a869e812a30db09"}, "outputs": [], "source": ["import os\n", "import requests\n", "import pandas as pd\n", "\n", "dataset = pd.read_csv(os.path.expanduser(\"~/data/primary.csv\"))\n", "dataset = dataset.drop([\"user_session\", \"user_id\", \"purchased\"], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "a994404866486131"}, "outputs": [], "source": ["requests.post(\n", "    \"http://34.117.58.199/predict\",  # Remplacer par l'adresse IP associ\u00e9e \u00e0 l'Ingress\n", "    json=dataset.sample(n=10).to_json()\n", ").json()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notre API est correctement d\u00e9ploy\u00e9e sur Kubernetes ! \ud83d\udc4f\n", "\n", "Il ne reste plus qu'\u00e0 automatiser le d\u00e9ploiement de l'API via un d\u00e9clencheur Cloud Build."]}, {"cell_type": "markdown", "metadata": {"break": "new"}, "source": ["## Configuration de Cloud Build\n", "\n", "Puisque nous sommes sur la branche `master`, il ne faut plus d\u00e9ployer l'image Docker vers Cloud Run. La derni\u00e8re \u00e9tape du fichier `cloudbuild.yaml` doit \u00eatre supprim\u00e9e."]}, {"cell_type": "raw", "metadata": {"format": "yaml"}, "source": ["# Liste des Cloud Builders : https://console.cloud.google.com/gcr/images/cloud-builders/GLOBAL\n", "steps:\n", "- name: \"gcr.io/cloud-builders/docker\"\n", "  id: Building Docker image\n", "  args: ['build', '-t', 'gcr.io/$PROJECT_ID/purchase-predict-api:$SHORT_SHA', '.']\n", "- name: 'gcr.io/cloud-builders/docker'\n", "  id: Pushing Docker image\n", "  args: ['push', 'gcr.io/$PROJECT_ID/purchase-predict-api:$SHORT_SHA']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comme pour la pr\u00e9-production, le d\u00e9clencheur va construire l'image Docker et l'envoyer vers le registre de conteneurs du projet Google Cloud. Il nous faut rajouter les autres \u00e9tapes qui vont prendre cette image Docker pour l'ins\u00e9rer dans les configurations Kubernetes. Pour rappel, l'image Docker se voit attribuer un tag qui correspond au 7 premi\u00e8res lettres du commit SHA de Git.\n", "\n", "> \u2753 Comment utiliser ce tag dans le fichier de configuration YAML ?\n", "\n", "Et oui, dans notre fichier `deployment.yaml`, nous devons sp\u00e9cifier le tag Docker \u00e0 utiliser. Comment pourrions-nous faire r\u00e9f\u00e9rence \u00e0 un tag *dynamique* d\u00e9termin\u00e9 lors du d\u00e9clenchement du build ?\n", "\n", "La solution consiste \u00e0 utiliser du **templating**.\n", "\n", "### Templating de fichier\n", "\n", "Le templating est un proc\u00e9d\u00e9 qui consiste \u00e0 \u00e9crire des r\u00e9f\u00e9rences \u00e0 des macros dans des fichiers de configuration, puis \u00e0 remplacer ces macros par des valeurs dynamiques lors du rendu. L'objectif est de pouvoir \u00e9crire des fichiers de configuration qui, \u00e0 tout moment, peuvent \u00eatre dynamiques en rempla\u00e7ant certaines valeurs selon des variables \u00e9crites dans le texte. Ce proc\u00e9d\u00e9 de templating est \u00e9galement pr\u00e9sent dans d'autres applications, dont Apache Airflow que nous verrons tr\u00e8s bient\u00f4t.\n", "\n", "L'id\u00e9e ici, c'est de ne pas utiliser un tag sp\u00e9cifique dans le fichier de Deployment, mais de faire r\u00e9f\u00e9rence \u00e0 une macro qui sera ensuite remplac\u00e9e au moment de l'ex\u00e9cution. Dans le fichier Deployment, nous modifions le tag en rempla\u00e7ant par la macro `DOCKER_TAG`."]}, {"cell_type": "raw", "metadata": {"format": "yaml"}, "source": ["spec:\n", "  containers:\n", "  - name: pod-purchase-predict\n", "    image: gcr.io/training-ml-engineer/purchase-predict-api:DOCKER_TAG"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nous pouvons ensuite construire la prochaine \u00e9tape du fichier `cloudbuild.yaml`."]}, {"cell_type": "raw", "metadata": {"format": "yaml"}, "source": ["- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n", "  id: Rendering templated K8s YAML file\n", "  entrypoint: /bin/sh\n", "  args:\n", "  - '-c'\n", "  - |\n", "     sed -s '$a---' k8s/*.yaml > config.yaml.tpl &&\n", "     sed \"s/DOCKER_TAG/${SHORT_SHA}/g\" config.yaml.tpl > config.yaml"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Analysons en d\u00e9tails cette \u00e9tape. Elle fait appel \u00e0 des commandes Bash.\n", "\n", "- La premi\u00e8re commande `sed` va avoir pour objectif de concat\u00e9ner l'ensemble des fichiers d'extension `*.yaml` \u00e0 l'int\u00e9rieur du dossier `k8s/` et de s\u00e9parer ces concat\u00e9nations par des sauts de lignes suivies de trois tirets. Le r\u00e9sultat est ensuite enregist\u00e9 dans le fichier `config.yaml.tpl`.\n", "- Encore avec la commande `sed`, on remplace la macro `DOCKER_TAG` du fichier `config.yaml.tpl` par les 7 premi\u00e8res lettres du commit SHA de Git, faisant r\u00e9f\u00e9rence au tag de l'image Docker construite par les \u00e9tapes pr\u00e9c\u00e9dentes. Le rendu du templating est ensuite enregistr\u00e9 dans le fichier `config.yaml`.\n", "\n", "L'int\u00e9r\u00eat d'avoir un seul fichier `config.yaml` c'est qu'il va \u00e0 la fois contenir le tag de l'image Docker construite juste avant, mais aussi car la mise \u00e0 jour des ressources sur K8s sera plus facile si toutes les configurations sont centralis\u00e9es dans un seul fichier.\n", "\n", "La derni\u00e8re \u00e9tape concerne le d\u00e9ploiement sur K8s."]}, {"cell_type": "raw", "metadata": {"format": "yaml"}, "source": ["- name: 'gcr.io/cloud-builders/kubectl'\n", "  id: Deploy to K8s\n", "  args:\n", "  - 'apply'\n", "  - '--namespace'\n", "  - 'api-purchase'\n", "  - '-f'\n", "  - 'config.yaml'\n", "  env:\n", "  - 'CLOUDSDK_COMPUTE_ZONE=europe-north1-b'\n", "  - 'CLOUDSDK_CONTAINER_CLUSTER=purchase-predict-api'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["L'environnement de build est `kubectl`, qui contient d\u00e9j\u00e0 toutes les d\u00e9pendances pour l'interface K8s. Nous utilisons un `apply` pour mettre \u00e0 jour les ressources, en pr\u00e9cisant l'espace de noms.\n", "\n", "Les variables d'environnements `CLOUDSDK_COMPUTE_ZONE` et `CLOUDSDK_CONTAINER_CLUSTER` sont n\u00e9cessaires pour que Cloud Build sache o\u00f9 et vers quel cluster ex\u00e9cuter la mise \u00e0 jour des ressources.\n", "\n", "Au final, le fichier `cloudbuild.yaml` contient 4 \u00e9tapes."]}, {"cell_type": "raw", "metadata": {"format": "yaml"}, "source": ["# Liste des Cloud Builders : https://console.cloud.google.com/gcr/images/cloud-builders/GLOBAL\n", "steps:\n", "- name: \"gcr.io/cloud-builders/docker\"\n", "  id: Building Docker image\n", "  args: ['build', '-t', 'gcr.io/$PROJECT_ID/purchase-predict-api:$SHORT_SHA', '.']\n", "- name: 'gcr.io/cloud-builders/docker'\n", "  id: Pushing Docker image\n", "  args: ['push', 'gcr.io/$PROJECT_ID/purchase-predict-api:$SHORT_SHA']\n", "- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n", "  id: Rendering templated K8s YAML file\n", "  entrypoint: /bin/sh\n", "  args:\n", "  - '-c'\n", "  - |\n", "     sed -s '$a---' k8s/*.yaml > config.yaml.tpl &&\n", "     sed \"s/DOCKER_TAG/${SHORT_SHA}/g\" config.yaml.tpl > config.yaml\n", "- name: 'gcr.io/cloud-builders/kubectl'\n", "  id: Deploy to K8s\n", "  args:\n", "  - 'apply'\n", "  - '--namespace'\n", "  - 'api-purchase'\n", "  - '-f'\n", "  - 'config.yaml'\n", "  env:\n", "  - 'CLOUDSDK_COMPUTE_ZONE=europe-north1-b'\n", "  - 'CLOUDSDK_CONTAINER_CLUSTER=purchase-predict-api'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nous pouvons maintenant cr\u00e9er un nouveau d\u00e9clencheur sur <a href=\"https://console.cloud.google.com/cloud-build/triggers\" target=\"_blank\">Cloud Build</a>.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod7.png\" />\n", "\n", "Avant de lancer une ex\u00e9cution, il est important d'autoriser Cloud Build \u00e0 interagir avec GKE, comme nous l'avions fait pour Cloud Run.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod9.png\" />\n", "\n", "Ajoutons les fichiers au r\u00e9f\u00e9rentiel Git puis poussons les nouvelles r\u00e9f\u00e9rences."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["git add .\n", "git commit -am \"Add K8s configuration files\"\n", "git push google master"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Apr\u00e8s quelques minutes d'ex\u00e9cution, le build devrait correctement se finaliser.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod8.png\" />\n", "\n", "En affichant les pods avec `kubectl get pods --namespace api-purchase`, nous voyons qu'ils sont beaucoup plus r\u00e9cents."]}, {"cell_type": "raw", "metadata": {"format": "console"}, "source": ["NAME                                READY   STATUS    RESTARTS   AGE\n", "purchase-predict-7656f97c5c-drj5k   1/1     Running   0          2m22s\n", "purchase-predict-7656f97c5c-qgnzs   1/1     Running   0          59s"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pour s'assurer qu'il s'agit de la bonne image Docker en cours d'ex\u00e9cution, nous pouvons chercher l'information en affichant le YAML du Deployment."]}, {"cell_type": "raw", "metadata": {"format": "bash"}, "source": ["kubectl get deploy purchase-predict -o yaml --namespace api-purchase | grep image:"]}, {"cell_type": "raw", "metadata": {"format": "console"}, "source": ["image: gcr.io/training-ml-engineer/purchase-predict-api:7828046"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Sur <a href=\"https://console.cloud.google.com/gcr/images\">Container Registry</a>, il s'agit bien de l'image la plus r\u00e9cente.\n", "\n", "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/k8s_prod10.png\" />\n", "\n", "Notre d\u00e9ploiement vers le cluster K8s est maintenant pleinement op\u00e9rationnel."]}, {"cell_type": "markdown", "metadata": {"type": "ending"}, "source": ["## \u2714\ufe0f Conclusion\n", "\n", "Nous y sommes presque ! Plus qu'une derni\u00e8re \u00e9tape pour avoir notre pipeline de production.\n", "\n", "- Nous avons configur\u00e9 un cluster K8s pour l'environnement de production.\n", "- Nous avons d\u00e9fini des fichiers de configuration YAML.\n", "- Le d\u00e9ploiement de l'API a \u00e9t\u00e9 automatis\u00e9 via Cloud Build.\n", "\n", "> \u27a1\ufe0f Il ne reste plus qu'\u00e0 construire le pipeline de production en entier pour avoir un environnement 100% automatis\u00e9."]}], "metadata": {"celltoolbar": "\u00c9diter les M\u00e9ta-Donn\u00e9es", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.0"}}, "nbformat": 4, "nbformat_minor": 4}