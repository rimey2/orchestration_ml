{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "intro"
   },
   "source": [
    "**MLflow** est une plateforme open source qui permet de g√©rer le cycle de vie des mod√®les de Machine Learning. En particulier, gr√¢ce √† MLflow, les mod√®les qui ont √©t√© entra√Æn√©s √† une date sp√©cifique ainsi que les hyper-param√®tres associ√©s pourront √™tre stock√©s, monitor√©s et r√©-utilis√©s de mani√®re efficace.\n",
    "\n",
    "<img src=\"https://dv495y1g0kef5.cloudfront.net/training/data_engineer_uber/img/mlflow.png\" width=\"300\" />\n",
    "\n",
    "<blockquote><p>üôã <b>Ce que nous allons faire</b></p>\n",
    "<ul>\n",
    "    <li>D√©couvrir les concepts importants de MLflow</li>\n",
    "    <li>Tracker et monitorer des mod√®les en local</li>\n",
    "    <li>Installer MLflow sur un serveur et envoyer les mod√®les sur le serveur</li>\n",
    "</ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts de MLflow\n",
    "\n",
    "Rappelons-nous du workflow en Machine Learning : la premi√®re √©tape de collecte des donn√©es et suivie d'une √©tape de transformation des donn√©es, puis de la mod√©lisation pour maximiser une m√©trique de performance qui jugera de la qualit√© de l'algorithme employ√©. √ätre productif avec du Machine Learning n'est pas de tout repos pour les raisons suivantes.\n",
    "\n",
    "- **Il est difficile de garder un trace des pr√©c√©dentes exp√©riences**. Une chose √† laquelle beaucoup de Data Scientists font face, c'est de faire une s√©rie d'exp√©riences en modifiant algorithmes et param√®tres, mais qui peut s'av√©rer contre-productif si l'on ne dispose pas de l'historique des mod√®les et de leurs performances. Bien que Kedro puisse tendre vers cette pratique, il ne permet pas de le faire enti√®rement √† lui tout seul.\n",
    "- **Il est difficile de reproduire le code**. Dans les projets Data Science, une multitude de fonctions permettent d'arriver √† un r√©sultat bien pr√©cis : le changement de quelques lignes de code peut grandement affecter le mod√®le et ses performances.\n",
    "- **Il n'y a aucun standard sur le packaging et le d√©ploiement de mod√®les**. Chaque √©quipe poss√®de son approche pour d√©ployer les mod√®les, et ce sont souvent les grandes √©quipes avec de l'exp√©rience qui peuvent se le permettre.\n",
    "- **Il n'y a aucun point central pour g√©rer les mod√®les**. En pratique, la solution na√Øve consiste √† sauvegarder les param√®tres dans des fichiers sur le m√™me serveur h√©bergeant l'algorithme, en stockage local avec Kedro.\n",
    "\n",
    "MLflow cherche √† am√©liorer la productivit√© en offrant la possibilit√© de r√©-entra√Æner, r√©-utiliser et d√©ployer des mod√®les en agissant sur un point central (plateforme MLflow) o√π tout l'historique du mod√®le sera conserv√©.\n",
    "\n",
    "Tout d'abord, MLflow est *language-agnostic*, c'est-√†-dire que les mod√®les peuvent √™tre cod√©s en Python, R, Java ou encore C++ et envoy√©s sur MLflow. Ensuite, il n'y a aucun pr√©-requis concernant la librairie de Machine Learning : que vous soyez adeptes de `scikit-learn` ou de `tensorflow`, tout sera compatible.\n",
    "\n",
    "Quatre composants r√©sident sous MLflow.\n",
    "\n",
    "- **MLflow Tracking** est l'API et l'interface utilisateur pour logger les hyper-param√®tres, le versioning de code et les *artifacts* (param√®tres du mod√®le, fichier de poids, ...).\n",
    "- **MLflow Projects** est un format standard pour package un code source et le r√©-utiliser dans plusieurs projets.\n",
    "- **MLflow Models** est un format de packaging pour les mod√®les de Machine Learning.\n",
    "- **MLflow Registry** est le registre de mod√®le (comme un git de mod√®les) qui permet de s'assurer que les mod√®les respectent certaines contraintes.\n",
    "\n",
    "Hormis le composant *Projects*, qui est remplac√© par l'utilisation de Kedro, nous utiliserons tous les composants de MLflow pour g√©rer efficacement le cycle de vie des mod√®les.\n",
    "\n",
    "Pour installer MLflow en local, il suffit juste d'ex√©cuter `pip install mlflow` dans le terminal (d√©j√† install√© dans l'environnement Blent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc3a1f4589b82456"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn # Wrapper pour scikit-learn\n",
    "\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import f1_score, PrecisionRecallDisplay, precision_recall_curve, plot_precision_recall_curve\n",
    "\n",
    "X_train = pd.read_csv(os.path.expanduser(\"~/data/X_train.csv\"))\n",
    "X_test = pd.read_csv(os.path.expanduser(\"~/data/X_test.csv\"))\n",
    "y_train = pd.read_csv(os.path.expanduser(\"~/data/y_train.csv\")).values.flatten()\n",
    "y_test = pd.read_csv(os.path.expanduser(\"~/data/y_test.csv\")).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aab245b0cd2f94b"
   },
   "outputs": [],
   "source": [
    "# Hyper-param√®tres des mod√®les\n",
    "hyp_params = {\n",
    "    \"num_leaves\": 60,\n",
    "    \"min_child_samples\": 10,\n",
    "    \"max_depth\": 12,\n",
    "    \"n_estimators\": 100,\n",
    "    \"learning_rate\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ensuite lancer un *experiment* sous MLflow. Pour cela, cr√©ons une nouvelle exp√©rience que l'on nommera `purchase_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "784caa07be54e053"
   },
   "outputs": [],
   "source": [
    "# Identification de l'interface MLflow\n",
    "mlflow.set_tracking_uri(\"file://\" + os.path.expanduser('~/mlruns'))\n",
    "\n",
    "mlflow.set_experiment(\"purchase_predict\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model = LGBMClassifier(**hyp_params, objective=\"binary\", verbose=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # On calcule le score du mod√®le sur le test\n",
    "    score = f1_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    mlflow.log_params(hyp_params)\n",
    "    mlflow.log_metric(\"f1\", score)\n",
    "    \n",
    "    print(mlflow.get_artifact_uri())\n",
    "    mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ex√©cutant ce code, nous avons d√©clenc√© un **run** avec `mlflow.start_run()`. L'int√©r√™t d'utiliser `with` est qu'en sortant de l'indentation, le run MLflow sera automatiquement termin√©. Nous allons envoyer plusieurs informations vers MLflow.\n",
    "\n",
    "- Les hyper-param√®tres du mod√®le avec `log_params`.\n",
    "- La ou les m√©triques obtenues sur un √©chantillon avec `log_metric`.\n",
    "- Le mod√®le au format de `scikit-learn` avec `log_model`.\n",
    "\n",
    "En <a href=\"https://jupyterhub-multiplex.blent.ai/user-redirect/MLflow/\" target=\"_blank\">visualisant l'interface web MLflow</a>, nous voyons le mod√®le appara√Ætre avec les informations associ√©es.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/mlflow1.png\" />\n",
    "\n",
    "En cliquant sur la date d'ex√©cution, nous avons acc√®s √† plus de d√©tails ainsi qu'aux fichiers stock√©s (ici le mod√®le), que l'on appelle des **artifacts**.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/mlflow2.png\" />\n",
    "\n",
    "√Ä noter qu'il est √©galement possible de r√©cup√©rer l'historique des mod√®les entra√Æn√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85a323fe1352ddcb"
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient(\n",
    "    tracking_uri=\"file://\" + os.path.expanduser('~/mlruns')\n",
    ")\n",
    "\n",
    "client.get_metric_history(run.info.run_id, key='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser efficacement MLflow, il faut architecturer le code source afin qu'il soit r√©-utilisable et facilement manipulable par les Data Scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a2f89560c034769"
   },
   "outputs": [],
   "source": [
    "def save_pr_curve(X, y, model):\n",
    "    plt.figure(figsize=(16,11))\n",
    "    prec, recall, _ = precision_recall_curve(y, model.predict_proba(X)[:,1], pos_label=1)\n",
    "    pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot(ax=plt.gca())\n",
    "    plt.title(\"PR Curve\", fontsize=16)\n",
    "    plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "    plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1, 0))\n",
    "    plt.savefig(os.path.expanduser(\"~/data/pr_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def train_model(params):\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model = LGBMClassifier(**params, objective=\"binary\", verbose=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        score = f1_score(y_test, model.predict(X_test))\n",
    "        save_pr_curve(X_test, y_test, model)\n",
    "\n",
    "        mlflow.log_params(hyp_params)\n",
    "        mlflow.log_metric(\"f1\", score)\n",
    "        mlflow.log_artifact(os.path.expanduser(\"~/data/pr_curve.png\"), artifact_path=\"plots\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä chaque appel de la fonction `train_model`, une instance du mod√®le est entra√Æn√©e sur la base d'entra√Ænement avec des hyper-param√®tres sp√©cifiques. La fonction `save_pr_curve` d√©velopp√©e permet d'enregistrer le graphique de la courbe PR dans un fichier. Cela permet notamment d'envoyer les graphiques √† MLflow sous forme d'artifacts.\n",
    "\n",
    "Chaque appel de la fonction `train_model` va donc entra√Æner un mod√®le LightGBM, en calculer des m√©triques, des graphiques et envoyer le r√©sultats sous forme de run sur MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1feb58acdece926"
   },
   "outputs": [],
   "source": [
    "train_model({**hyp_params, **{'n_estimators': 200, 'learning_rate': 0.05}})\n",
    "train_model({**hyp_params, **{'n_estimators': 500, 'learning_rate': 0.025}})\n",
    "train_model({**hyp_params, **{'n_estimators': 1000, 'learning_rate': 0.01}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apr√®s ex√©cution, les trois runs sont bien pr√©sents.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/mlflow3.png\" />\n",
    "\n",
    "L√†-aussi, en explorant un run en particulier, nous pouvons voir appara√Ætre le graphique dans l'explorateur de fichiers.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/mlflow4.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "break": "new"
   },
   "source": [
    "## Installation sur un serveur\n",
    "\n",
    "Pour √™tre pleinement exploit√©, MLflow **doit √™tre install√© sur un serveur** : en plus de pouvoir collaborer √† plusieurs, cela permettra de l'int√©grer dans un √©cosyst√®me avec un syst√®me de stockage de fichiers et de processus automatis√©s.\n",
    "\n",
    "Lan√ßons une VM avec Debian 10 avec une instance de type `g1-small`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo apt update && sudo apt install python3-pip -y\n",
    "sudo pip3 install mlflow google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, les artifacts sont stock√©s dans le syst√®me local o√π est ex√©cut√© le code Python : MLflow ne peut donc pas recevoir et afficher ces artifacts. Il est donc n√©cessaire de configurer un bucket dans lequel MLflow pourra stocker et retrouver les artifacts que l'on enverra.\n",
    "\n",
    "Par d√©faut, MLflow √©tant install√© sur une VM dans notre projet Google Cloud, les autorisations sont d√©j√† pr√©sentes sur la machine, permettant √† MLflow de lire des fichiers depuis le bucket. En revanche, il est n√©cessaire de d√©finir les autorisations pour les applications qui vont envoyer ou r√©cup√©rer des mod√®les vers MLflow. Pour des raisons de s√©curit√©, nous allons ajouter un compte de service qui aura un r√¥le de lecture et √©criture sur ce bucket uniquement.\n",
    "\n",
    "Rajoutons un compte de service qui aura les deux r√¥les suivants : **Cr√©ateur des objets de l'espace de stockage** et **Lecteur des objets de l'espace de stockage**. Pour terminer, nous allons cr√©er une cl√© et conserver en lieu s√ªr le fichier JSON.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/mlflow5.png\" />\n",
    "\n",
    "Pour s'assurer de la bonne ex√©cution de MLflow, il est pr√©f√©rable de cr√©er un `systemd` plut√¥t que de lancer MLflow en arri√®re plan depuis le terminal."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo nano /etc/systemd/system/mlflow.service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Il faut penser √† modifier le nom du bucket <code>gs://blent-formation-ml-engineer-data/mlflow</code>.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "systemd"
   },
   "source": [
    "[Unit]\n",
    "Description=MLflow\n",
    "After=network.target \n",
    "\n",
    "[Service]\n",
    "Restart=on-failure\n",
    "RestartSec=30\n",
    "ExecStart=mlflow server --default-artifact-root gs://blent-formation-ml-engineer-data/mlflow --backend-store-uri sqlite:///mlflow.db --host 0.0.0.0 --port 80\n",
    "\n",
    "[Install]\n",
    "WantedBy=multi-user.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La derni√®re √©tape consiste √† activer le service et √† l'ex√©cuter. Avec `daemon-reload`, nous activons le service MLflow."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo systemctl daemon-reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toujours dans la gestion des services Cloud, il faut appr√©hender le cas d'un red√©marrage de la VM et relancer automatiquement le service MLflow au d√©marrage."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo systemctl enable mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on lance le service."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo systemctl start mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, en visitant la page web √† l'adresse IP externe de la VM, l'interface MLflow appara√Æt.\n",
    "\n",
    "Rajoutons la cl√© JSON que nous avons t√©l√©charg√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee0f6d2b16489e9f"
   },
   "outputs": [],
   "source": [
    "%%writefile ~/data/mlflow-key.json\n",
    "# TODO : Coller ici le contenu de la cl√© JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour sp√©cifier vers quel serveur nous allons envoyer les artifacts et le mod√®le, il faut sp√©cifier le nom de domaine ou l'adresse IP avec `set_tracking_uri`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b9905a124a5b28c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "# Authentification √† Google Cloud avec la cl√© correspondant au compte de service MLflow\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.expanduser(\"~/data/mlflow-key.json\")\n",
    "\n",
    "# Nouvel URI de l'interface MLflow\n",
    "mlflow.set_tracking_uri(\"http://34.107.0.37\")\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cr√©ons une nouvelle exp√©rience sur le serveur MLflow et ex√©cutons un *run*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d33b4c9ec39f2899"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"purchase_predict\")\n",
    "\n",
    "def train_model(params):\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model = LGBMClassifier(**params, objective=\"binary\", verbose=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        score = f1_score(y_test, model.predict(X_test))\n",
    "        save_pr_curve(X_test, y_test, model)\n",
    "\n",
    "        mlflow.log_params(hyp_params)\n",
    "        mlflow.log_metric(\"f1\", score)\n",
    "        mlflow.log_artifact(os.path.expanduser(\"~/data/pr_curve.png\"), artifact_path=\"plots\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dor√©navant, toutes les ex√©cutions seront envoy√©s sur le serveur contenant MLflow et les artifacts stock√©s dans le bucket associ√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c48122a1d10114dd"
   },
   "outputs": [],
   "source": [
    "train_model({**hyp_params, **{'n_estimators': 200, 'learning_rate': 0.05}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voil√† ! L'interface MLflow devrait √† pr√©sent afficher le mod√®le stock√© sur Google Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "ending"
   },
   "source": [
    "## ‚úîÔ∏è Conclusion\n",
    "\n",
    "Nous pouvons d√©sormais tracker les mod√®les de Machine Learning avec MLflow.\n",
    "\n",
    "- Nous avons utilis√© MLflow en local pour tracker les mod√®les.\n",
    "- Nous avons install√© MLflow sur un serveur en stockant les artifacts sur un Cloud Storage.\n",
    "\n",
    "> ‚û°Ô∏è Maintenant que nous avons notre mod√®le de Machine Learning et un versioning de mod√®le, nous pouvons mettre en place une API pour exposer le mod√®le."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "√âditer les M√©ta-Donn√©es",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
