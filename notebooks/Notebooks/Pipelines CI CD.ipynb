{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "intro"
   },
   "source": [
    "√Ä partir de maintenant, nous allons rentrer en plein dans l'approche MLOps pour automatiser le d√©ploiement de mod√®les de Machine Learning. L'automisation implique d'organiser efficacement son environnement, et fait intervenir une multitude d'outils qui peuvent porter √† confusion. La premi√®re brique concernant l'automatisation se fait directement √† partir des d√©p√¥ts sources, puisque c'est √† partir d'eux que toutes les ex√©cutions de l'infrastructure d√©pendent.\n",
    "\n",
    "<blockquote><p>üôã <b>Ce que nous allons faire</b></p>\n",
    "<ul>\n",
    "    <li>D√©couvrir l'approche CI/CD pour automatiser les r√©f√©rentiels</li>\n",
    "    <li>Construire un pipeline CI/CD d'entra√Ænement du mod√®le</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/gGldiUgAUOJ04g1Ves/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines CI/CD\n",
    "\n",
    "L'approche CI/CD, bien connue des DevOps, permet d'am√©liorer la fr√©quence de distribution des applications en impl√©mentant des d√©clenchements automatis√©s. L'objectif de cette approche est de garantir que les nouvelles fonctionnalit√©s ou am√©liorations d'un code/application s'int√®grent correctement dans un environnement et puisse √™tre directement d√©ploy√© sans intervention humaine.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/cicd1.png\" />\n",
    "\n",
    "Plus pr√©cis√©ment, nous pouvons diff√©rencier d'une part l'acronyme ¬´ CI ¬ª de l'acronyme ¬´ CD ¬ª.\n",
    "\n",
    "- L'**int√©gration continue** (CI) vise √† s'assurer que de nouvelles fonctionnalit√©s logicielles vont correctement s'int√©grer dans un environnement existant par l'interm√©diaire de tests et de fusion de code. Avec l'int√©gration continue, il est possible de travailler √† plusieurs sur un m√™me r√©f√©rentiel en harmonisant les fonctionnalit√©s gr√¢ce aux tests.\n",
    "- Le **d√©ploiement continu** (CD) consiste √† transf√©rer automatiquement le code produit vers un environnement de production. C'est notamment pertinent lorsque l'on souhaite toujours avoir une version √† jour en production.\n",
    "\n",
    "Tr√®s souvent, le d√©ploiement continu est r√©alis√© apr√®s ex√©cution de l'int√©gration continue : si un ou plusieurs tests √©chouent, alors nous ne souhaitons pas lancer le d√©ploiement puisque l'application ne valide pas les tests associ√©s. Le fait d'automatiser ces deux s√©quences, en plus d'augmenter l'efficacit√© op√©rationnelle par l'automatisation, vont fortement r√©duire le risque d'erreur humaine. Une fois que le pipeline CI/CD est en place, il y a peu de chances que ce dernier g√©n√®re une erreur (en dehors de l'application elle-m√™me). Cela permet de garantir que toutes les configurations seront appliqu√©es √† chaque ex√©cution du pipeline, l√† o√π un d√©veloppeur pourrait oublier certaines configurations lorsqu'il y en a beaucoup.\n",
    "\n",
    "Par exemple, dans notre cas, nous aimerions **automatiser les tests unitaires** √† chaque fois que nous mettons √† jour le projet `purchase_predict`. De m√™me, nous souhaiterions **entra√Æner automatiquement** le mod√®le √† chaque fois qu'une nouvelle version de code est envoy√©e vers le d√©p√¥t.\n",
    "\n",
    "Il existe plusieurs outils permettant de construire des pipelines CI/CD. On retrouve notamment en open-source **Jenkins**, tr√®s populaire ou encore **Travis CI**. Du c√¥t√© des fournisseurs Cloud, nous avons **Code Build** du c√¥t√© de Google et **CodePipeline** du c√¥t√© d'AWS.\n",
    "\n",
    "## Environnements\n",
    "\n",
    "Dans les bonnes pratiques de d√©veloppement, il est d'usage de s√©parer l'environnement de **production** et l'environnement de **pr√©-production** (ou *staging*). Ceci est en partie h√©rit√© des cycles d'int√©gration continue : lorsqu'une application passe avec succ√®s les tests et le d√©ploiement, cette derni√®re peut tout de m√™me g√©n√©rer des erreurs qui sont dues √† ses interactions dans un environnement d√©j√† existant. Par exemple, une fonctionnalit√© de l'application a √©t√© mise √† jour, et l'int√©gration continue de l'application passe tous les tests. N√©anmoins, d'autres applications dans l'environnement n'ont pas √©t√© mises √† jour en cons√©quence, et d√©ployer la nouvelle version de l'application dans l'environnement risquerait de cr√©er des erreurs de communication entre les applications.\n",
    "\n",
    "C'est ainsi tout l'int√©r√™t de **l'environnement de pr√©-production**. Il s'agit d'une r√©plique (plus ou moins fid√®le) de l'environnement de production, potentiellement √† une plus petite √©chelle pour limiter les co√ªts, qui simule l'environnement de production dans lequel seule nous y avons acc√®s. Ainsi, plut√¥t que d'envoyer directement l'application en production, nous pouvons tout d'abord l'envoyer en pr√©-production, v√©rifier que cette derni√®re s'int√®gre bien avec les autres services, avant de l'envoyer d√©finitivement en production. Ainsi, on s'assure qu'en production, il n'y aura pas d'erreurs, et la transition sera *en th√©orie* invisible pour les utilisateurs.\n",
    "\n",
    "Ces pratiques sont h√©rit√©es des grandes entreprises, qui dispose d'environnements tr√®s cons√©quents, mais √©galement des infrastructures en microservices, o√π il y a beaucoup d'interactions entre les services. Dans le cas d'une application monolithique, cette s√©paration √† moins de sens, mais dans le cas de microservices, elle devient indispensable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "break": "new"
   },
   "source": [
    "## Pipeline CI/CD du mod√®le\n",
    "\n",
    "Construisons le pipeline CI/CD qui se charge d'entra√Æner un mod√®le optimis√© : le projet `purchase_predict`.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/pipeline_training.png\" />\n",
    "\n",
    "\n",
    "Le pipeline d'entra√Ænement du mod√®le peut √™tre scind√© en deux √©tapes.\n",
    "\n",
    "- √Ä l'aide de Spark, nous effectuons la collecte et la transformation des donn√©es vers un dossier contenant des fichiers CSV dans le bucket Cloud Storage.\n",
    "- Avec Cloud Build, nous ex√©cutons Kedro pour r√©cup√©rer les donn√©es, effectuer l'encodage et optimiser le mod√®le pour ensuite l'envoyer vers MLflow.\n",
    "\n",
    "L'avantage de cette repr√©sentation est que la premi√®re √©tape peut s'ex√©cuter de mani√®re asynchrone par rapport √† la premi√®re : plusieurs ex√©cutions peuvent √™tre r√©alis√©es avec Cloud Build sans avoir besoin de relancer le code Spark √† chaque fois.\n",
    "\n",
    "### Cloud Build\n",
    "\n",
    "Le service <a href=\"https://console.cloud.google.com/cloud-build/builds\" target=\"_blank\">Cloud Build</a> permet de g√©n√©rer des builds et/ou de compiler des applications en serverless.\n",
    "\n",
    "Cr√©ons le fichier `install.sh` √† la racine du projet `purchase_predict`. Dans ce fichier Bash, nous allons y ins√©rer les commandes permettant d'installer les d√©pendances n√©cessaire dans un environnement vierge."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "kedro install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier `requirements.txt` contient toutes les d√©pendances **avec leurs versions sp√©cifiques**. Ce fichier est important il va s'assurer que les d√©pendances install√©es seront identiques √† celles de la production."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "plaintext"
   },
   "source": [
    "python-dotenv==0.15.0\n",
    "pandas==1.1.5\n",
    "scikit-learn==0.23.2\n",
    "xgboost==1.3.0.post0\n",
    "lightgbm==3.1.1\n",
    "hyperopt==0.2.5\n",
    "mlflow==1.12.1\n",
    "kedro==0.17.0\n",
    "kedro-viz==3.10.1\n",
    "google-cloud-storage==1.34.0\n",
    "gcsfs==0.6.2\n",
    "seaborn==0.11.0\n",
    "pre-commit==2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline CI\n",
    "\n",
    "Commen√ßons dans un premier temps √† configurer le pipeline **d'int√©gration continue** du projet `purchase_predict`. Les diff√©rentes √©tapes de configuration de Cloud Build sont √† d√©finir dans un fichier `cloudbuild.yaml` √† la racine du projet."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "yaml"
   },
   "source": [
    "# Liste des Cloud Builders : https://console.cloud.google.com/gcr/images/cloud-builders/GLOBAL\n",
    "steps:\n",
    "- name: \"docker.io/library/python:3.8\"\n",
    "  id: CI\n",
    "  entrypoint: /bin/sh\n",
    "  args:\n",
    "  - -c\n",
    "  - 'chmod a+x install.sh && ./install.sh && pytest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons chaque champ de ce fichier. Le param√®tre `steps` va permettre de d√©finir diff√©rentes √©tapes ind√©pendantes qui seront ex√©cut√©es s√©quentiellement par Cloud Build. √Ä noter que dans le cas de notre pipeline CI, nous n'avons pour l'instant qu'une seule √©tape.\n",
    "\n",
    "Ensuite, nous allons configurer cette √©tape. Dans un premier temps, nous sp√©cifions dans `name` l'image Docker √† utiliser pour ex√©cuter le pipeline. Nous utilisons celle propos√©e par d√©faut pour Python 3.8, mais la <a href=\"https://console.cloud.google.com/gcr/images/cloud-builders/GLOBAL\" target=\"_blank\">liste des Cloud Builders</a> poss√®de diff√©rentes images. Ensuite, avec `id`, nous lui attribuons un identifiant/nom. Les deux autres champs vont sp√©cifier la commande √† ex√©cuter.\n",
    "\n",
    "- Le champ `entrypoint` sp√©cifie le programme √† ex√©cuter. Il peut s'agit, comme ici, de l'interpr√©teur Bash, mais cela peut √©galement faire r√©f√©rence √† un autre interpr√©teur ou √† une application tierce.\n",
    "- La liste `args` contient les arguments qui seront pass√©s en param√®tres au programme.\n",
    "\n",
    "Il est en th√©orie possible de tout condenser en une seule ligne sur `entrypoint`, mais l'avantage du champ `args` est que la lecture des diff√©rents arguments sous forme de liste est plus lisible, notamment lorsqu'il y en a beaucoup.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Il n'est pas possible d'avoir plusieurs points d'entr√©e pour une m√™me √©tape. Par exemple, il ne sera pas possible d'ex√©cuter plusieurs commandes Bash en une seule √©tape.\n",
    "</div>\n",
    "\n",
    "C'est d'ailleurs pour cette raison que l'on utilise `&&` ici pour ex√©cuter plusieurs commandes Bash les unes √† la suite des autres. Lorsqu'il y a beaucoup de commandes Bash √† utiliser, il est pr√©f√©rable de les ajouter dans un fichier comme `install.sh` et de garder dans la configuration Cloud Build uniquement les commandes importantes comme l'installation globale ou l'ex√©cution propre √† cette √©tape.\n",
    "\n",
    "Les arguments permettent de donner les droits d'ex√©cution √† l'utilisateur dans l'environnement Cloud Build (`a+x`), nous ex√©cution le fichier `install.sh` pour y installer les d√©pendances de Kedro et enfin, nous lan√ßons les tests unitaires avec `pytest`.\n",
    "\n",
    "Dans Cloud Build, cr√©ons un nouveau d√©clencheur que nous appelerons `build-purchase-predict-staging`.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/cloud_build1.png\" />\n",
    "\n",
    "Ce d√©clencheur sera appel√© d√®s lors qu'un push sera effectu√© sur le d√©p√¥t Cloud Source `purchase_predict`. Nous pouvons sp√©cifier la branche avec `staging` sous forme d'expression r√©guli√®re. Ce d√©clencheur en concerne dont **que l'environnement de pr√©-production**.\n",
    "\n",
    "Apr√®s avoir cr√©e le d√©clencheur, nous pouvons envoyer de nouvelles r√©f√©rences vers le d√©p√¥t."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "git add .\n",
    "git commit -am \"Added Cloud Build configuration file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si besoin, il faut ajouter la cl√© SSH √† l'agent pour nous authentifier."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "c\"\n",
    "chmod 600 ~/ssh/git_key\n",
    "ssh-add ~/ssh/git_key\n",
    "git push google staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le futur, pour √©viter de toujours faire cette manipulation, il est possible d'ajouter les trois premi√®res lignes au fichier `~/.bashrc`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cat <<EOT >> ~/.bashrc\n",
    "eval \"$(ssh-agent -s)\" > /dev/null 2>&1\n",
    "chmod 600 ~/ssh/git_key\n",
    "ssh-add ~/ssh/git_key > /dev/null 2>&1\n",
    "EOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans <a href=\"https://console.cloud.google.com/cloud-build/builds\" target=\"_blank\">l'historique de compilation</a>, un nouveau build devrait appara√Ætre.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/cloud_build2.png\" />\n",
    "\n",
    "Au bout de plusieurs minutes, une fois que l'environnement a install√© toutes les d√©pendances, les tests sont lanc√©s. S'il n'y a pas d'erreur, c'est que les tests unitaires de `pytest` ont r√©ussis.\n",
    "\n",
    "### Pipeline CD\n",
    "\n",
    "Ajoutons maintenant une nouvelle √©tape au fichier `cloudbuild.yaml`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "yaml"
   },
   "source": [
    "# Liste des Cloud Builders : https://console.cloud.google.com/gcr/images/cloud-builders/GLOBAL\n",
    "steps:\n",
    "- name: \"docker.io/library/python:3.8\"\n",
    "  id: CI\n",
    "  entrypoint: /bin/sh\n",
    "  args:\n",
    "  - -c\n",
    "  - 'chmod a+x install.sh && ./install.sh && pytest'\n",
    "- name: \"docker.io/library/python:3.8\"\n",
    "  id: CD\n",
    "  entrypoint: /bin/sh\n",
    "  args:\n",
    "  - -c\n",
    "  - 'chmod a+x install.sh && ./install.sh && kedro run --pipeline global'\n",
    "  env:\n",
    "  - 'ENV=$BRANCH_NAME'\n",
    "  - 'MLFLOW_SERVER=$_MLFLOW_SERVER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette deuxi√®me √©tape ressemble fortement √† la premi√®re, √† la diff√©rence que nous ex√©cutons le pipeline `global` de Kedro, et nous ajoutons deux variables d'environnement dans la liste `env`.\n",
    "\n",
    "- La premi√®re variable d'environnement `ENV`, utilis√©e pour versionner le mod√®le sur MLflow, r√©cup√®re la valeur de `BRANCH_NAME`, qui sera automatiquement remplac√© par Cloud Build par la branche sur laquelle s'ex√©cute le d√©clencheur. Ainsi, il n'y a pas besoin de sp√©cifier pr√©cis√©ment `staging` ou `production`, puisque cela d√©pendra du nom de la branche Git.\n",
    "- La deuxi√®me variable `MLFLOW_SERVER` fait r√©f√©rence √† l'adresse du serveur MLflow. Ce qui est particulier est que nous utilisons une **variable de substitution** `_MLFLOW_SERVER`. En effet, il n'est pas possible de mettre le nom de domaine de MLflow parce que Cloud Build ne s'ex√©cute pas dans le VPC (r√©seau local) contenant l'instance MLflow : il n'aura donc pas la possibilit√© de r√©soudre le nom de domaine. Nous allons alors ajouter cette variable de substition dans les param√®tres du d√©clencheur pour surcharger la variable d'environnement.\n",
    "\n",
    "Pour cela, modifions le d√©clencheur et ajoutons-y la substitution avec l'adresse IP du serveur MLflow.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/cloud_build3.png\" />\n",
    "\n",
    "Apr√®s avoir mis √† jour le fichier `cloudbuild.yaml`, nous pouvons de nouveau envoyer les nouvelles r√©f√©rences vers le d√©p√¥t."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "git commit -am \"Added CD pipeline in Cloud Build configuration file\"\n",
    "git push google staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/cloud_build4.png\" />\n",
    "\n",
    "Ce qui est int√©ressant, c'est que l'√©tape CD ne sera ex√©cut√©e que si l'√©tape CI est ex√©cut√©e sans erreurs. On √©vite donc d'entra√Æner des mod√®les si les **tests unitaires ne sont pas v√©rifi√©es**, √©vitant ainsi des temps et de la consommation de ressources inutiles.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Dans certains cas, il se peut que l'entra√Ænement des mod√®les prenne du temps. Or, Cloud Build est limit√© par d√©faut √† un temps d'ex√©cution maximal de 10 minutes.\n",
    "</div>\n",
    "\n",
    "Si l'on n√©cessite de plus grandes ressources, il est possible d'ajouter un champ `options` dans le fichier de configuration Cloud Build pour sp√©cifier le type de machine √† utiliser et le temps d'ex√©cution maximal."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "yaml"
   },
   "source": [
    "options:\n",
    "  machineType: 'N1_HIGHCPU_8'\n",
    "timeout: 1200s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ici une machine de type `N1_HIGHCPU_8` avec un `timeout` (temps d'ex√©cution maximal) de 20 minutes (au lieu de 10 minutes par d√©faut). La liste des types de machines Cloud Build disponible est <a href=\"https://cloud.google.com/cloud-build/pricing?hl=fr\" target=\"_blank\">accessible ici</a>.\n",
    "\n",
    "Pour les tests, on pourra baisser le nombre d'it√©rations du processus d'optimisation (√† $4$ par exemple) afin de r√©duire les temps d'ex√©cutions.\n",
    "\n",
    "Sur l'interface MLflow, nous pouvons voir que le mod√®le optimis√© a bien √©t√© r√©cup√©r√© et versionn√© vers l'√©tat `Staging`.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/cloud_build5.png\" />\n",
    "\n",
    "Pour synth√©tiser, nous avons cr√©e le pipeline suivant.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/cicd2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "ending"
   },
   "source": [
    "## ‚úîÔ∏è Conclusion\n",
    "\n",
    "Nous venons de cr√©er notre premier pipeline automatis√© ! üòé\n",
    "\n",
    "- Nous avons vu l'approche CI/CD et pourquoi elle √©tait indispensable.\n",
    "- Nous avons construit un pipeline CI/CD pour entra√Æner automatiquement le mod√®le.\n",
    "\n",
    "> ‚û°Ô∏è Dans le suite, nous allons construire **l'int√©gralit√© du pipeline de pr√©-production**, des tests unitaires jusqu'au d√©ploiement sur Cloud Run."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "√âditer les M√©ta-Donn√©es",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
