{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "intro"
   },
   "source": [
    "Avec Docker, il est tr√®s facile de conteneuriser une application pour packager le code source et ses d√©pendances. Nous allons donc pouvoir conteneuriser l'API contenant le mod√®le.\n",
    "\n",
    "<blockquote><p>üôã <b>Ce que nous allons faire</b></p>\n",
    "<ul>\n",
    "    <li>Cr√©er l'image Docker contenant l'API.</li>\n",
    "    <li>Configurer le syst√®me pour ex√©cuter automatiquement le conteneur sur l'instance Docker.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/XeAE4MvXVwOLZsZJWO/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation de l'image Docker\n",
    "\n",
    "Nous allons construire l'image Docker qui va contenir l'API du mod√®le. Pour cela, nous devrions a priori ajouter une cl√© SSH au d√©p√¥t Cloud Source pour que l'instance `docker` puisse cloner le projet. Mais profitons de l'interaction entre les services de Google Cloud : il est possible de donner des droits d'acc√®s automatiquement √† certaines VMs pour, par exemple, authentifier les actions de clonage Git.\n",
    "\n",
    "Cr√©ons une VM `docker`. En modifiant les informations de l'instance, nous pouvons d√©finir le **Niveau d'acc√®s** √† *D√©finir l'acc√®s pour chaque API*. Sous Cloud Source Repositoires, s√©lectionnons *Lecture seule*.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/docker_api1.png\" />\n",
    "\n",
    "Enregistrons les param√®tres et d√©marrons l'instance. En s'y connectant en SSH, nous pouvons cloner le d√©p√¥t `purchase_predict_api` depuis <a href=\"https://source.cloud.google.com/\" target=\"_blank\">Cloud Source</a>. En cliquant sur le bouton pour cloner, copions la commande via **SDK Google Cloud**. La commande de clonage via SSH ne fonctionnera pas puisque nous n'avons pas configur√© de cl√©s."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "gcloud source repos clone purchase_predict_api --project=xxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sur le d√©p√¥t, il faut se positionner sur la branche `staging`, puisqu'il n'y a aucun fichier par d√©faut."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "cd purchase_predict_api/\n",
    "git checkout staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retournons dans le r√©pertoire local et ajoutons le fichier `Dockerfile`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "Dockerfile"
   },
   "source": [
    "FROM python:3.8-slim\n",
    "\n",
    "# Indispensable pour LightGBM\n",
    "RUN apt update\n",
    "RUN apt install libgomp1 -y\n",
    "\n",
    "# Mise √† jour de pip3\n",
    "RUN pip install --upgrade pip\n",
    "RUN python3 --version\n",
    "\n",
    "RUN mkdir /app\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt /app/requirements.txt\n",
    "COPY app.py /app/app.py\n",
    "COPY src/ /app/src/\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# On ouvre et expose le port 80\n",
    "EXPOSE 80\n",
    "\n",
    "# Lancement de l'API\n",
    "# Attention : ne pas lancer en daemon !\n",
    "CMD [\"gunicorn\", \"app:app\", \"-b\", \"0.0.0.0:80\", \"-w\", \"4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce fichier est d√©compos√© en plusieurs √©tapes.\n",
    "\n",
    "- L'installation des paquets n√©cessaires (comme `libgomp1` pour LightGBM) et du gestionnaire `pip`.\n",
    "- L'ajout des fichiers sources dans le dossier `/app` sur l'image Docker.\n",
    "- L'ex√©cution en parall√®le des 4 processus Flask avec `gunicorn`.\n",
    "\n",
    "Une fois le fichier enregistr√©, nous pouvons construire l'image."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo docker build -t purchase_predict_api:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite ex√©cuter un conteneur avec l'image construire."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo docker run -p 0.0.0.0:80:80 purchase_predict_api:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, au bout de quelques secondes ... plusieurs erreurs apparaissent !"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "console"
   },
   "source": [
    "Traceback (most recent call last):\n",
    "  File \"/usr/local/lib/python3.8/site-packages/gunicorn/arbiter.py\", line 583, in spawn_worker\n",
    "    worker.init_process()\n",
    "  File \"/usr/local/lib/python3.8/site-packages/gunicorn/workers/base.py\", line 119, in init_process\n",
    "    self.load_wsgi()\n",
    "  File \"/usr/local/lib/python3.8/site-packages/gunicorn/workers/base.py\", line 144, in load_wsgi\n",
    "    self.wsgi = self.app.wsgi()\n",
    "  File \"/usr/local/lib/python3.8/site-packages/gunicorn/app/base.py\", line 67, in wsgi\n",
    "    self.callable = self.load()\n",
    "  File \"/usr/local/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py\", line 49, in load\n",
    "    return self.load_wsgiapp()\n",
    "  File \"/usr/local/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py\", line 39, in load_wsgiapp\n",
    "    return util.import_app(self.app_uri)\n",
    "  File \"/usr/local/lib/python3.8/site-packages/gunicorn/util.py\", line 358, in import_app\n",
    "    mod = importlib.import_module(module)\n",
    "  File \"/usr/local/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
    "    return _bootstrap._gcd_import(name[level:], package, level)\n",
    "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
    "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
    "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
    "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
    "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
    "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
    "  File \"/app/app.py\", line 4, in <module>\n",
    "    from src.model import Model\n",
    "  File \"/app/src/__init__.py\", line 9, in <module>\n",
    "    raise Exception(\"Environment variable {} must be defined.\".format(env_var))\n",
    "Exception: Environment variable ENV must be defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet, nous n'avons pas d√©fini les **variables d'environnement** ! Il faut donc sp√©cifier au conteneur Docker les variables telles que nous les avions d√©finies dans le fichier `.env` par exemple. Pour cela, il est plus commode de cr√©er un fichier `env.list` par exemple."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "plaintext"
   },
   "source": [
    "ENV=staging\n",
    "MLFLOW_SERVER=http://xx.xx.xx.xx/\n",
    "MLFLOW_REGISTRY_NAME=purchase_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour passer l'ensembles des variables en param√®tre au conteneur Docker, nous pouvons utiliser l'argument `--env-file`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo docker run --env-file ./env.list -p 0.0.0.0:80:80 purchase_predict_api:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 4 ex√©cutions de l'API doivent maintenant √™tre op√©rationnelles dans le conteneur.\n",
    "\n",
    "> ‚ùì Comment avons-nous pu r√©cup√©rer le mod√®le depuis Cloud Storage alors qu'il n'y a pas de compte de service ?\n",
    "\n",
    "En effet, nous n'avons pas sp√©cifi√© de compte de service ici. C'est justement parce que nous sommes sur **une VM situ√©e dans le m√™me projet que le bucket** que l'authentification s'effectue par d√©faut. Les instances de VM de Google Cloud ont d√©j√† des comptes de service par d√©faut avec notamment un acc√®s en lecture et √©criture vers Cloud Storage. Ainsi, cela est automatiquement transmis au conteneur Docker. Par contre, si nous √©tions sur un serveur d'un autre projet Google Cloud ou d'un autre fournisseur Cloud, alors il aurait fallu mettre la cl√© d'un compte de service sur l'instance h√¥te, renseigner le chemin √† cette cl√© dans la variable `GOOGLE_APPLICATION_CREDENTIALS` et transmettre cette variable d'environnement au conteneur Docker.\n",
    "\n",
    "Testons notre API pour voir que tout s'est bien d√©roul√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7a095396fda32904"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(os.path.expanduser(\"~/data/primary.csv\"))\n",
    "dataset = dataset.drop([\"user_session\", \"user_id\", \"purchased\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b23d8bf95fdd7e7"
   },
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"http://xx.xx.xx.xx/predict\",  # Remplacer par l'adresse IP de l'instance Docker\n",
    "    json=dataset.sample(n=10).to_json()\n",
    ").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "break": "new"
   },
   "source": [
    "## Configuration du syst√®me\n",
    "\n",
    "Nous sommes capable d'ex√©cuter notre API √† partir d'un conteneur Docker. Seulement, nous devons r√©aliser toutes ces √©tapes manuellement si l'on souhaite par exemple cr√©er une autre VM pour l'API ou si l'on red√©marre l'actuelle VM. Pour optimiser la configuration du syst√®me, nous allons mettre en place plusieurs composantes.\n",
    "\n",
    "- L'image Docker va √™tre h√©berg√© vers un <a href=\"https://console.cloud.google.com/gcr/images\" target=\"_blank\">Container Registry</a> qui ne sera accessible que dans notre projet GCP (et non public).\n",
    "- Nous allons utiliser le nom d'h√¥te de l'instance MLflow plut√¥t que son adresse IP : en effet, en cas de red√©marrage de cette instance, l'adresse IP publique, √©tant √©ph√©m√®re par d√©faut, sera modifi√©e. Ainsi, il faut modifier **toutes les r√©f√©rences** de cette adresse IP dans les applications qui l'utilisent. Le nom d'h√¥te, quant √† lui, permettra de faire r√©f√©rence √† cette VM m√™me en cas de red√©marrage.\n",
    "- Un service syst√®me sera cr√©e pour ex√©cuter automatiquement le conteneur contenant l'API.\n",
    "\n",
    "### Registre de conteneurs Google Cloud\n",
    "\n",
    "Dirigeons-nous vers le <a href=\"https://console.cloud.google.com/gcr/images\" target=\"_blank\">Container Registry</a> et cr√©ons un nouveau registre comme nous l'avions fait avec DockerHub.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/docker_api2.png\" />\n",
    "\n",
    "Comme nous pouvons le voir, il n'y a aucun registre pour l'instant. Mais contrairement √† DockerHub, il n'est pas possible d'en cr√©er un directement via l'interface : les registres sont automatiquement cr√©es lorsqu'une image est envoy√©e via l'API Google Cloud.\n",
    "\n",
    "Arr√™tons la VM Docker et attribuons lui un nouvel acc√®s API au stockage.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/docker_api3.png\" />\n",
    "\n",
    "Maintenant, nous disposons des droits d'acc√®s pour envoyer une image vers un conteneur de notre projet. Toujours en SSH, apr√®s red√©marrage et connexion √† l'instance Docker, ex√©cutons les commandes `gcloud` pour s'authentifier."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo gcloud auth login\n",
    "sudo gcloud auth configure-docker"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "console"
   },
   "source": [
    "WARNING: Your config file at [/root/.docker/config.json] contains these credential helper entries:\n",
    "\n",
    "{\n",
    "  \"credHelpers\": {\n",
    "    \"gcr.io\": \"gcloud\",\n",
    "    \"us.gcr.io\": \"gcloud\",\n",
    "    \"eu.gcr.io\": \"gcloud\",\n",
    "    \"asia.gcr.io\": \"gcloud\",\n",
    "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
    "    \"marketplace.gcr.io\": \"gcloud\"\n",
    "  }\n",
    "}\n",
    "Adding credentials for all GCR repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de `sudo` est importante, car cela va cr√©er les fichiers de configuration dans `/root`, car Docker est utilis√© avec `sudo`. Avant d'envoyer l'image vers le registre, attribuons-lui un tag permettant de faire r√©f√©rence √† notre projet Google Cloud."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo docker tag purchase_predict_api gcr.io/training-ml-engineer/purchase_predict_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'√† envoyer l'image vers le registre."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo docker push gcr.io/training-ml-engineer/purchase_predict_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le registre est bien cr√©e avec l'image.\n",
    "\n",
    "<img src=\"https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/training/ml_engineer_facebook/img/docker_api4.png\" />\n",
    "\n",
    "### Nom de domaine du serveur MLflow\n",
    "\n",
    "Avant de configurer les fichiers `systemd` pour ex√©cuter automatiquement le conteneur sur la machine, r√©cup√©rons le nom de domaine de l'instance MLflow. Apr√®s connexion SSH, nous pouvons simplement utiliser la commande suivante."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "hostname -f"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "console"
   },
   "source": [
    "mlflow.europe-west3-c.c.training-ml-engineer.internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on retourne sur l'instance Docker, en SSH, nous pouvons faire un `ping` pour v√©rifier que le nom de domaine correspond bien √† l'instance MLflow."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "ping -c 5 mlflow.europe-west3-c.c.training-ml-engineer.internal"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "console"
   },
   "source": [
    "PING mlflow.europe-west3-c.c.training-ml-engineer.internal (10.156.0.3) 56(84) bytes of data.\n",
    "64 bytes from mlflow.europe-west3-c.c.training-ml-engineer.internal (10.156.0.3): icmp_seq=1 ttl=64 time=108 ms\n",
    "64 bytes from mlflow.europe-west3-c.c.training-ml-engineer.internal (10.156.0.3): icmp_seq=2 ttl=64 time=105 ms\n",
    "64 bytes from mlflow.europe-west3-c.c.training-ml-engineer.internal (10.156.0.3): icmp_seq=3 ttl=64 time=105 ms\n",
    "64 bytes from mlflow.europe-west3-c.c.training-ml-engineer.internal (10.156.0.3): icmp_seq=4 ttl=64 time=105 ms\n",
    "64 bytes from mlflow.europe-west3-c.c.training-ml-engineer.internal (10.156.0.3): icmp_seq=5 ttl=64 time=105 ms\n",
    "\n",
    "--- mlflow.europe-west3-c.c.training-ml-engineer.internal ping statistics ---\n",
    "5 packets transmitted, 5 received, 0% packet loss, time 10ms\n",
    "rtt min/avg/max/mdev = 105.004/105.730/107.661/0.999 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä noter que ce nom de domaine n'est accessible **qu'√† l'int√©rieur du projet Google Cloud** : la VM ne sera pas joignable depuis son propre ordinateur."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "console"
   },
   "source": [
    "ping: mlflow.europe-west3-c.c.training-ml-engineer.internal: Nom ou service inconnu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration du `systemd`\n",
    "\n",
    "La derni√®re √©tape consiste √† cr√©er un service `systemd` qui permettra d'ex√©cuter automatiquement le conteneur en arri√®re-plan tout en garantissant le red√©marrage. Mais avant, rappelons-nous que les variables d'environnements doivent √™tre configur√©s, et avec un `systemd`, il n'est pas possible faire des `export`.\n",
    "\n",
    "Pour pouvoir configurer les variables d'environnements pour un service, il faut les centraliser dans un fichier de configuration, que nous allons cr√©er avec `sudo nano /etc/default/purchase_predict_api`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "plaintext"
   },
   "source": [
    "ENV=staging\n",
    "MLFLOW_SERVER=http://mlflow.europe-west3-c.c.training-ml-engineer.internal/\n",
    "MLFLOW_REGISTRY_NAME=purchase_predict\n",
    "DOCKER_IMAGE=gcr.io/training-ml-engineer/purchase_predict_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'√† cr√©er le fichier `systemd`. Ce fichier concentre trois blocs que nous allons expliciter.\n",
    "\n",
    "- **Unit** fait r√©f√©rence aux unit√©s qui doivent √™tre au pr√©alable en cours d'ex√©cution pour que ce service puisse √™tre lanc√©. En l'occurence, les services r√©seaux et de gestion de fichier doivent √™tre lanc√©s pour Zookeeper.\n",
    "- **Service** contient les informations du service.\n",
    "- **Install** sp√©cifie la m√©thode d'installation du service.\n",
    "\n",
    "On pourra trouver <a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/chap-managing_services_with_systemd\" target=\"_blank\">plus d'informations ici</a> pour les fichiers `systemd`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo nano /etc/systemd/system/purchase_predict_api.service"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "systemd"
   },
   "source": [
    "[Unit]\n",
    "Description=API Container\n",
    "After=docker.service\n",
    "Requires=docker.service\n",
    "\n",
    "[Service]\n",
    "EnvironmentFile=/etc/default/purchase_predict_api\n",
    "TimeoutStartSec=0\n",
    "Restart=always\n",
    "ExecStartPre=-/usr/bin/docker stop $DOCKER_IMAGE\n",
    "ExecStartPre=-/usr/bin/docker rm $DOCKER_IMAGE\n",
    "ExecStartPre=/usr/bin/docker pull $DOCKER_IMAGE\n",
    "ExecStart=/usr/bin/docker run --env-file /etc/default/purchase_predict_api -p 0.0.0.0:80:80 $DOCKER_IMAGE\n",
    "\n",
    "[Install]\n",
    "WantedBy=multi-user.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apr√®s avoir enregistr√© le fichier, nous activons le service et l'ajoutons au services syst√®mes √† d√©marrer automatiquement."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo systemctl daemon-reload\n",
    "sudo systemctl enable /etc/systemd/system/purchase_predict_api.service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis d√©marrons le service."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo systemctl start purchase_predict_api.service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour v√©rifier si le conteneur est bien ex√©cut√©, nous pouvons v√©rifier que le port $80$ est bien utilis√©."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "netstat -ltpn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "console"
   },
   "source": [
    "Active Internet connections (only servers)\n",
    "Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \n",
    "tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      -                   \n",
    "tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   \n",
    "tcp6       0      0 :::22                   :::*                    LISTEN      -    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le port $80$ n'est pas utilis√©, il se peut que le conteneur ne soit pas en cours d'ex√©cution. Pour cela, il est possible d'inspecter les sorties du syst√®me en affichant par exemple les 100 derni√®res lignes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "format": "bash"
   },
   "source": [
    "sudo journalctl -u purchase_predict_api.service | tail -n 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons une nouvelle fois l'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e1546cad0ea915e0"
   },
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"http://xx.xx.xx.xx/predict\",  # Remplacer par l'adresse IP de l'instance Docker\n",
    "    json=dataset.sample(n=10).to_json()\n",
    ").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red√©marrons l'instance. A priori, si nous avons correctement configur√© le `systemd`, le conteneur devra s'ex√©cuter automatiquement au d√©marrage de l'instance. Apr√®s quelques secondes, le temps que l'instance red√©marre, nous pouvons ex√©cuter √† nouveau la cellule ci-dessus.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Puisque l'instance poss√®de une adresse IP √©ph√©m√®re, il faudra probablement changer l'IP dans le cellule.\n",
    "</div>\n",
    "\n",
    "Une fois termin√©, nous pouvons stopper l'instance puisque nous n'allons plus l'utiliser par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "type": "ending"
   },
   "source": [
    "## ‚úîÔ∏è Conclusion\n",
    "\n",
    "Notre API est maintenant pleinement d√©ploy√©e.\n",
    "\n",
    "- Nous avons cr√©er une image Docker pour l'API.\n",
    "- Nous avons configur√© le syst√®me pour automatiser l'ex√©cution de l'API.\n",
    "\n",
    "> ‚û°Ô∏è Malgr√© tout, jusqu'ici, le travail √©tait principalement manuel. √Ä partir de maintenant, nous allons pleinement int√©grer l'approche MLOps en <b>automatisant le d√©ploiement</b> des diff√©rents projets."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "√âditer les M√©ta-Donn√©es",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
